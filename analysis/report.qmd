---
title: "Learning from Twins: Can marketers learn about consumers across the political divide by interacting with AI"
author: "Benjamin Lira"
date: today
format:
  html: default
  pdf: 
    keep-tex: true
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
library(tidyverse)
library(arrow)
library(lme4)
library(lmerTest)
library(modelsummary)
library(gt)
library(ggplot2)
library(ggpubr)
library(patchwork)
library(emmeans)
library(tinytable)
library(jsonlite)

# switch for data load.
is_running_in_quarto <- function() {
  # Check if a Quarto-specific environment variable is set
  return(Sys.getenv("QUARTO_DOCUMENT_PATH") != "")
}

# Example usage:
if (is_running_in_quarto()) {
  dat <- read_parquet("../data/processed/cleaned_data.parquet")
} else {
 dat <- read_parquet("./data/processed/cleaned_data.parquet")
}


# Load cleaned data


# Define consistent color scheme: Democrats = blue, Republicans = red
party_colors <- c("Democrat" = "#0015BC", "Republican" = "#E81B23")

# Define learner party colors (D→R = Democrat learning about Republicans, R→D = Republican learning about Democrats)
learner_party_colors <- c("D→R" = "#0015BC", "R→D" = "#E81B23")

# Define common coefficient mapping for all modelsummary tables
coef_map_common <- c(
  "timepost" = "Time (Post)",
  "learner_partyR→D" = "Learner Party (R→D)",
  "political_extremism" = "Political Extremism",
  "timepost:learner_partyR→D" = "Time × Learner Party",
  "timepost:political_extremism" = "Time × Extremism",
  "learner_partyR→D:political_extremism" = "Learner Party × Extremism",
  "timepost:learner_partyR→D:political_extremism" = "Time × Learner Party × Extremism",
  "accuracy_pre" = "Baseline Accuracy",
  "warmth_outgroup_pre" = "Baseline Warmth",
  "confidence_outgroup_pre" = "Baseline Confidence",
  "info" = "Bot Informativeness",
  "empathy" = "Bot Empathy",
  "user_turn_count" = "Turn Count",
  "log_word_count" = "Log(Word Count)",
  "SD (Intercept ResponseID)" = "SD(Intercept)"
)
```

## Overview

Political polarization creates challenges for marketers who must communicate effectively with ideologically diverse consumers. Misperceptions about political outgroups are widespread, with partisans often holding exaggerated and inaccurate views of those across the political divide. These misperceptions can lead to ineffective marketing strategies when firms attempt to appeal to broad consumer bases. This study tests whether interacting with an AI chatbot prompted to represent a political outgroup can improve marketers' understanding of that outgroup and reduce affective polarization.

### Hypotheses

We hypothesized that after interacting with an AI chatbot representing their political outgroup, participants would:

1. "**Report more accurate beliefs** about the outgroup's attitudes toward environmentally responsible consumption."
2. "**Report warmer feelings** toward the political outgroup."

## Data

### Data Collection

We collected data via Qualtrics from `r nrow(dat)` participants. Participants self-reported their political orientation on a 0-100 slider scale, where values below 50 indicate Democratic leaning and values 50 and above indicate Republican leaning.

```{r participant-breakdown}
dat %>%
  count(learner_party) %>%
  gt() %>%
  cols_label(learner_party = "Learner Party", n = "N") %>%
  tab_header(title = "Sample Composition")
```

### Measures

We measured two primary outcomes to assess belief updating and affective change.

- **Belief accuracy**: Absolute difference between participants' estimates of outgroup green attitudes and actual outgroup means (lower = more accurate)
- **Outgroup warmth**: Feeling thermometer (0-100 scale) toward the political outgroup

Additionally, we collected confidence in outgroup judgments (5-point scale) and bot informativeness and empathy ratings (5-point scale)

### Pre-Registered Analyses

For each primary outcome, we estimated mixed-effects models of the form:

$$y \sim \text{time} \times \text{learner\_party} + (1 | \text{id})$$

where `time` indexes pre- versus post-interaction measurement and `learner_party` indicates D→R versus R→D learning direction.

## Results

```{r prepare-long-data}
# Prepare long format datasets
accuracy_long <- dat %>%
  select(ResponseId, learner_party, accuracy_pre, accuracy_post) %>%
  pivot_longer(cols = c(accuracy_pre, accuracy_post), names_to = "time",
               names_pattern = "accuracy_(pre|post)", values_to = "error") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

warmth_long <- dat %>%
  select(ResponseId, learner_party, warmth_outgroup_pre, warmth_outgroup_post) %>%
  pivot_longer(cols = c(warmth_outgroup_pre, warmth_outgroup_post), names_to = "time",
               names_pattern = "warmth_outgroup_(pre|post)", values_to = "warmth") %>%
  mutate(time = factor(time, levels = c("pre", "post")))
```

### Preliminaries

Most participants held strong partisan identities, with the majority in the top and bottom quartiles of the political spectrum.

```{r}
#| fig-height: 3
#| fig-width: 4
dat %>% 
  ggplot(aes(politicalorientation_1)) + 
  geom_histogram(aes(fill = after_stat(x))) + 
  labs(x = 'Political Orientation', y = "Count")+
  theme(legend.position = "none")+
  scale_fill_gradient2(low = party_colors["Democrat"], 
                       mid = "gray40", 
                       high = party_colors["Republican"],
                       midpoint = 50)  # Adjust midpoint to your scale center
```

The figure below compares actual green values with perceived ingroup and outgroup attitudes for Democrats and Republicans. The actual gap at baseline was much smaller than participants perceived. Perceptions of the ingroup are much more accurate.

```{r preliminaries, fig.width=6, fig.height=4}
# Prepare data for faceted plot
prelim_data <- dat %>%
  select(learner_party, participant_party, green_own, green_ingroup, green_outgroup_pre, green_outgroup_post) %>%
  pivot_longer(cols = c(green_own, green_ingroup, green_outgroup_pre, green_outgroup_post),
               names_to = "measure_type", values_to = "value") %>%
  mutate(
    measure_type = factor(measure_type,
                          levels = c("green_own", "green_ingroup", "green_outgroup_pre", "green_outgroup_post"),
                          labels = c("Own Attitudes", "Ingroup Perception", "Outgroup Perception\n(Pre)", "Outgroup Perception\n(Post)")),
    participant_party = factor(participant_party, levels = c("Democrat", "Republican"))
  )

# Create faceted plot
ggplot(prelim_data, aes(x = participant_party, y = value, fill = participant_party)) +
  stat_summary(fun = mean, geom = "bar", alpha = 0.8) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  facet_wrap(~measure_type, ncol = 4) +
  scale_fill_manual(values = party_colors, name = "Political Party") +
  labs(
    title = "Green Attitudes: Actual and Perceived",
    subtitle = "Own attitudes, ingroup perceptions, and outgroup perceptions before and after interaction",
    x = "Political Party",
    y = "Green Attitude (1-5 scale)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold"),
    legend.position = "none"
  )
```

```{r bias}
# Calculate baseline bias comparison
bias_test <- dat %>%
  select(learner_party, accuracy_pre) %>%
  rstatix::t_test(accuracy_pre~learner_party)

p <- bias_test %>% pull(p)

d <- dat %>%
  select(learner_party, accuracy_pre) %>%
  rstatix::cohens_d(accuracy_pre~learner_party) %>% pull(effsize) %>% Ben::numformat()

# Calculate means and SDs by group
bias_descriptives <- dat %>%
  group_by(learner_party) %>%
  summarise(
    mean_bias = mean(accuracy_pre, na.rm = TRUE),
    sd_bias = sd(accuracy_pre, na.rm = TRUE)
  )

mean_dr <- bias_descriptives %>% filter(learner_party == "D→R") %>% pull(mean_bias)
sd_dr <- bias_descriptives %>% filter(learner_party == "D→R") %>% pull(sd_bias)
mean_rd <- bias_descriptives %>% filter(learner_party == "R→D") %>% pull(mean_bias)
sd_rd <- bias_descriptives %>% filter(learner_party == "R→D") %>% pull(sd_bias)
```

What is the distribution of bias? At baseline, Democrats were more biased about Republicans (*M* = `r sprintf("%.2f", mean_dr)`, *SD* = `r sprintf("%.2f", sd_dr)`) than Republicans were about Democrats (*M* = `r sprintf("%.2f", mean_rd)`, *SD* = `r sprintf("%.2f", sd_rd)`), *d* = `r d`, *p* = `r sprintf("%.3f", p)`.

```{r bias-distribution}
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3

# Overall distribution
p1 <- dat %>%
  ggplot(aes(x = accuracy_pre)) +
  geom_density(color = NA, fill = "gray30", alpha = 0.6) +
  labs(
    title = "Overall Distribution",
    x = "Baseline Accuracy (higher = more accurate)",
    y = "Density"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))

# By participant party
p2 <- dat %>%
  ggplot(aes(x = accuracy_pre, fill = participant_party)) +
  geom_density(color = NA, alpha = 0.6) +
  scale_fill_manual(
    values = c("Democrat" = "steelblue", "Republican" = "firebrick"),
    name = "Participant Party"
  ) +
  labs(
    title = "By Participant Party",
    x = "Baseline Accuracy (higher = more accurate)",
    y = "Density"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = c(0.85, 0.85),
    legend.background = element_rect(fill = "white", color = "gray80", linewidth = 0.3)
  )

p1
p2
```

Does baseline accuracy correlate with baseline warmth? We examine whether people who are more biased about the outgroup also feel colder toward them.

```{r baseline-accuracy-warmth-correlation}
#| fig-width: 6
#| fig-height: 4

dat %>%
  ggplot(aes(x = accuracy_pre, y = warmth_outgroup_pre, color = participant_party)) +
  geom_point(alpha = 0.6, size = 2.5) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = party_colors, name = "Political Party") +
  labs(
    title = "Relationship Between Baseline Accuracy and Warmth",
    x = "Baseline Accuracy (higher = more accurate)",
    y = "Baseline Warmth (0-100 scale)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

Does baseline confidence predict baseline accuracy? We examine whether more confident participants are less accurate in their judgments, consistent with Dunning-Kruger effects.

```{r baseline-accuracy-confidence-correlation}
#| fig-width: 6
#| fig-height: 4

dat %>%
  ggplot(aes(x = confidence_outgroup_pre, y = accuracy_pre, color = participant_party)) +
  geom_point(alpha = 0.6, size = 2.5) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = party_colors, name = "Political Party") +
  labs(
    title = "Relationship Between Baseline Confidence and Accuracy",
    subtitle = "Testing for Dunning-Kruger effects",
    x = "Baseline Confidence (1-5 scale)",
    y = "Baseline Accuracy (higher = more accurate)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

### Q1. Do people update their beliefs after interacting with the chatbot?

```{r q1-data-prep}
# Calculate summary statistics for plots
accuracy_summary <- accuracy_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_error = mean(error, na.rm = TRUE),
            se_error = sd(error, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")

warmth_summary <- warmth_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_warmth = mean(warmth, na.rm = TRUE),
            se_warmth = sd(warmth, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")
```



```{r q1-models}
# Estimate mixed-effects models
accuracy_model0 <- lmer(error ~ time  + (1 | ResponseId), data = accuracy_long)
warmth_model0 <- lmer(warmth ~ time  + (1 | ResponseId), data = warmth_long)

accuracy_model <- lmer(error ~ time * learner_party + (1 | ResponseId), data = accuracy_long)
warmth_model <- lmer(warmth ~ time * learner_party + (1 | ResponseId), data = warmth_long)

# Extract coefficients for inline reporting
accuracy_time_coef <- fixef(accuracy_model0)["timepost"]
warmth_time_coef <- fixef(warmth_model0)["timepost"]


```

We examined whether participants changed their beliefs about the outgroup's environmental attitudes from pre- to post-interaction, analyzing both accuracy and warmth. As shown in the table above, participants became significantly more accurate (improving by `r sprintf("%.2f", accuracy_time_coef)` points on the 5-point scale) and warmer toward the outgroup (increasing by `r sprintf("%.1f", warmth_time_coef)` degrees on the 100-point thermometer).

```{r q1-plots}
#| fig-width: 10
#| fig-height: 4

# Combine plots side by side using patchwork
p_accuracy <- ggplot(accuracy_summary, aes(x = time, y = mean_error, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_error - se_error, ymax = mean_error + se_error), width = 0.1) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(title = "Belief Accuracy", x = "Time", y = "Mean Accuracy") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")

p_warmth <- ggplot(warmth_summary, aes(x = time, y = mean_warmth, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_warmth - se_warmth, ymax = mean_warmth + se_warmth), width = 0.1) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(title = "Outgroup Warmth", x = "Time", y = "Mean Warmth") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")

p_accuracy + p_warmth + plot_layout(guides = "collect") & theme(legend.position = "bottom")
```

```{r}
# Display models side by side
modelsummary(
  list(
    "Accuracy" = accuracy_model0,
    "Warmth" = warmth_model0),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  coef_map = coef_map_common,
  notes = "Note: Accuracy is negative absolute error (higher = more accurate). * p<0.05, ** p<0.01, *** p<0.001"
)
```

Do changes in accuracy correlate with changes in warmth? We examine whether people who became more accurate also became warmer toward the outgroup.

```{r accuracy-warmth-change-correlation}
#| fig-width: 6
#| fig-height: 4

# Create change scores for this analysis (reusing from later section)
dat_with_changes <- dat %>%
  mutate(
    accuracy_change = accuracy_post - accuracy_pre,  # Negative = improvement
    warmth_change = warmth_outgroup_post - warmth_outgroup_pre
  )

dat_with_changes %>%
  ggplot(aes(x = accuracy_change, y = warmth_change, color = learner_party)) +
  geom_point(alpha = 0.6, size = 2.5) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    title = "Relationship Between Accuracy Change and Warmth Change",
    x = "Accuracy Change (Negative = Improvement)",
    y = "Warmth Change (Positive = Increase)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

### Q2. Is belief updating symmetric across political groups?

```{r}
# Get simple effects
accuracy_contrasts <- emmeans(accuracy_model, ~ time | learner_party) %>%
  contrast("pairwise") %>%
  tidy()

warmth_contrasts <- emmeans(warmth_model, ~ time | learner_party) %>%
  contrast("pairwise") %>%
  tidy()

# Extract values for inline reporting
acc_dr_est <- abs(accuracy_contrasts$estimate[1])  # D→R effect (negative = improvement)
acc_dr_p <- accuracy_contrasts$p.value[1]
acc_rd_est <- abs(accuracy_contrasts$estimate[2])  # R→D effect
acc_rd_p <- accuracy_contrasts$p.value[2]

warmth_dr_est <- warmth_contrasts$estimate[1]  # D→R effect
warmth_dr_p <- warmth_contrasts$p.value[1]
warmth_rd_est <- warmth_contrasts$estimate[2]  # R→D effect
warmth_rd_p <- warmth_contrasts$p.value[2]

# Get interaction term from model
acc_interaction_coef <- fixef(accuracy_model)["timepost:learner_partyR→D"]
acc_interaction_p <- summary(accuracy_model)$coefficients["timepost:learner_partyR→D", "Pr(>|t|)"]

warmth_interaction_coef <- fixef(warmth_model)["timepost:learner_partyR→D"]
warmth_interaction_p <- summary(warmth_model)$coefficients["timepost:learner_partyR→D", "Pr(>|t|)"]

# Format for modelsummary
format_emmeans <- function(contrasts) {
  contrasts %>%
    mutate(
      stars = case_when(
        p.value < 0.001 ~ "***",
        p.value < 0.01 ~ "**",
        p.value < 0.05 ~ "*",
        TRUE ~ ""
      ),
      formatted = sprintf("%.3f%s", estimate, stars),
      se_formatted = sprintf("(%.3f)", std.error)
    )
}

acc_formatted <- format_emmeans(accuracy_contrasts)
warmth_formatted <- format_emmeans(warmth_contrasts)

rows = tibble(
    term = c("Time effect (Democrat)", "", "Time effect (Republican)", ""),
    `Accuracy` = c(acc_formatted$formatted[1], acc_formatted$se_formatted[1],
                   acc_formatted$formatted[2], acc_formatted$se_formatted[2]),
    `Warmth` = c(warmth_formatted$formatted[1], warmth_formatted$se_formatted[1],
                 warmth_formatted$formatted[2], warmth_formatted$se_formatted[2])
  )
attr(rows, "position") <- c(1, 2, 3, 4) # Inserts at rows 1 and 2

```

While both groups became more accurate, it was Democrats learning about Republicans who showed greater improvement (*b* = `r sprintf("%.2f", acc_dr_est)`, *p* `r if(acc_dr_p < 0.001) "< .001" else paste("=", sprintf("%.3f", acc_dr_p))`). Republicans also became less biased about Democrats, though to a lesser extent (*b* = `r sprintf("%.2f", acc_rd_est)`, *p* `r if(acc_rd_p < 0.001) "< .001" else paste("=", sprintf("%.3f", acc_rd_p))`). The interaction term was `r if(acc_interaction_p < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.2f", acc_interaction_coef)`, *p* `r if(acc_interaction_p < 0.001) "< .001" else paste("=", sprintf("%.3f", acc_interaction_p))`).

Both groups became warmer toward the outgroup at similar rates. Democrats learning about Republicans increased warmth by `r sprintf("%.1f", warmth_dr_est)` degrees (*p* `r if(warmth_dr_p < 0.001) "< .001" else paste("=", sprintf("%.3f", warmth_dr_p))`), while Republicans learning about Democrats increased by `r sprintf("%.1f", warmth_rd_est)` degrees (*p* `r if(warmth_rd_p < 0.001) "< .001" else paste("=", sprintf("%.3f", warmth_rd_p))`). The interaction was `r if(warmth_interaction_p < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.2f", warmth_interaction_coef)`, *p* `r if(warmth_interaction_p < 0.001) "< .001" else paste("=", sprintf("%.3f", warmth_interaction_p))`).

```{r}
# Create the table with add_rows
modelsummary(
  list("Accuracy" = accuracy_model, "Warmth" = warmth_model),
  stars = TRUE,
  add_rows = rows,
  gof_map = c("nobs", "r.squared"),
  coef_map = coef_map_common,
  notes = "Note: Accuracy is negative absolute error (higher = more accurate). * p<0.05, ** p<0.01, *** p<0.001"
) %>%
 strip_tt(line = TRUE) |>
    group_tt(i = list("Effects by Political Affiliation" = 1, "Full Regression Results" = 5)) |>
      style_tt(i = c(1, 6), bold = TRUE) |>
    style_tt(i = c(14, 16), line = "b", line_color = "lightgray")
```

### Q3. Does political extremity predict how much people update?

```{r extremism-models}
# Add extremism to long data
accuracy_long_ext <- accuracy_long %>%
  left_join(dat %>% select(ResponseId, political_extremism), by = "ResponseId")

warmth_long_ext <- warmth_long %>%
  left_join(dat %>% select(ResponseId, political_extremism), by = "ResponseId")

# First, test extremism predicting baseline outcomes
baseline_accuracy_extremism <- lm(accuracy_pre ~ political_extremism, data = dat)
baseline_warmth_extremism <- lm(warmth_outgroup_pre ~ political_extremism, data = dat)

# Extract coefficients for inline reporting
extremism_acc_baseline_b <- coef(baseline_accuracy_extremism)["political_extremism"]
extremism_acc_baseline_p <- summary(baseline_accuracy_extremism)$coefficients["political_extremism", "Pr(>|t|)"]

extremism_warmth_baseline_b <- coef(baseline_warmth_extremism)["political_extremism"]
extremism_warmth_baseline_p <- summary(baseline_warmth_extremism)$coefficients["political_extremism", "Pr(>|t|)"]

# Models with extremism interaction
accuracy_extremism_model <- lmer(
  error ~ time * learner_party * political_extremism + (1 | ResponseId),
  data = accuracy_long_ext
)

warmth_extremism_model <- lmer(
  warmth ~ time * learner_party * political_extremism + (1 | ResponseId),
  data = warmth_long_ext
)

# Extract three-way interaction terms for inline reporting
extremism_3way_acc_coef <- fixef(accuracy_extremism_model)["timepost:learner_partyR→D:political_extremism"]
extremism_3way_acc_p <- summary(accuracy_extremism_model)$coefficients["timepost:learner_partyR→D:political_extremism", "Pr(>|t|)"]

extremism_3way_warmth_coef <- fixef(warmth_extremism_model)["timepost:learner_partyR→D:political_extremism"]
extremism_3way_warmth_p <- summary(warmth_extremism_model)$coefficients["timepost:learner_partyR→D:political_extremism", "Pr(>|t|)"]


# Get simple effects at different extremism levels (low = -1 SD, high = +1 SD)
extremism_mean <- mean(accuracy_long_ext$political_extremism, na.rm = TRUE)
extremism_sd <- sd(accuracy_long_ext$political_extremism, na.rm = TRUE)

low_extremism = extremism_mean - extremism_sd
high_extremism = extremism_mean + extremism_sd

accuracy_extremism_contrasts <- emmeans(accuracy_extremism_model,
  ~ time | political_extremism,
  at = list(political_extremism = c(low_extremism, high_extremism))) %>%
  contrast("pairwise") %>%
  tidy()

warmth_extremism_contrasts <- emmeans(warmth_extremism_model, ~ time | political_extremism,
at = list(political_extremism = c(low_extremism, high_extremism))
) %>%
  contrast("pairwise") %>%
  tidy()

# Format simple effects
acc_ext_formatted <- accuracy_extremism_contrasts %>%
  mutate(
    stars = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    ),
    formatted = sprintf("%.3f%s", estimate, stars),
    se_formatted = sprintf("(%.3f)", std.error)
  )

warmth_ext_formatted <- warmth_extremism_contrasts %>%
  mutate(
    stars = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    ),
    formatted = sprintf("%.3f%s", estimate, stars),
    se_formatted = sprintf("(%.3f)", std.error)
  )

rows_extremism <- tibble(
  term = c("Time effect (Low Extremism)", "", "Time effect (High Extremism)", ""),
  `Accuracy` = c(acc_ext_formatted$formatted[1], acc_ext_formatted$se_formatted[1],
                 acc_ext_formatted$formatted[2], acc_ext_formatted$se_formatted[2]),
  `Warmth` = c(warmth_ext_formatted$formatted[1], warmth_ext_formatted$se_formatted[1],
               warmth_ext_formatted$formatted[2], warmth_ext_formatted$se_formatted[2])
)
attr(rows_extremism, "position") <- c(1, 2, 3, 4)
```

Politically extreme participants showed greater bias about the outgroup at baseline (*b* = `r sprintf("%.3f", extremism_acc_baseline_b)`, *p* `r if(extremism_acc_baseline_p < 0.001) "< .001" else paste("=", sprintf("%.3f", extremism_acc_baseline_p))`) and felt less warm toward them (*b* = `r sprintf("%.2f", extremism_warmth_baseline_b)`, *p* `r if(extremism_warmth_baseline_p < 0.001) "< .001" else paste("=", sprintf("%.3f", extremism_warmth_baseline_p))`). However, political extremism did not moderate the effect of the chatbot interaction. The three-way interaction for accuracy was `r if(extremism_3way_acc_p < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.3f", extremism_3way_acc_coef)`, *p* `r if(extremism_3way_acc_p < 0.001) "< .001" else paste("=", sprintf("%.3f", extremism_3way_acc_p))`), and for warmth was `r if(extremism_3way_warmth_p < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.2f", extremism_3way_warmth_coef)`, *p* `r if(extremism_3way_warmth_p < 0.001) "< .001" else paste("=", sprintf("%.3f", extremism_3way_warmth_p))`). More and less extreme participants were equally likely to update their beliefs and warmth toward the outgroup.

```{r}
# Display models
modelsummary(
  list("Accuracy" = accuracy_extremism_model, "Warmth" = warmth_extremism_model),
  stars = TRUE,
  add_rows = rows_extremism,
  coef_omit = "Intercept",
  gof_map = c("nobs", "r.squared"),
  coef_map = coef_map_common,
  notes = "Note: Time effects show pre-to-post change at Low Extremism (-1 SD) and High Extremism (+1 SD). Three-way interaction tests whether extremism moderates differential updating. * p<0.05, ** p<0.01, *** p<0.001"
) %>%
  strip_tt(line = TRUE) %>%
  group_tt(i = list("Simple Effects by Extremism Level" = 1, "Full Regression Results" = 5)) %>%
  style_tt(i = c(1, 6), bold = TRUE) %>%
  style_tt(i = c(20, 21), line = "b", line_color = "lightgray")
```

### Q4. Is belief updating associated with how the chatbot is perceived?

```{r process-models}
# Prepare data for regressions
dat_for_reg <- dat %>%
  filter(!is.na(accuracy_pre), !is.na(accuracy_post),
         !is.na(warmth_outgroup_pre), !is.na(warmth_outgroup_post),
         !is.na(info), !is.na(empathy))

# Process measure regressions
accuracy_process_model <- lm(accuracy_post ~ accuracy_pre + info + empathy, data = dat_for_reg)
warmth_process_model <- lm(warmth_outgroup_post ~ warmth_outgroup_pre + info + empathy, data = dat_for_reg)

# Extract coefficients for inline reporting
info_acc_b <- coef(accuracy_process_model)["info"]
info_acc_p <- summary(accuracy_process_model)$coefficients["info", "Pr(>|t|)"]
empathy_acc_b <- coef(accuracy_process_model)["empathy"]
empathy_acc_p <- summary(accuracy_process_model)$coefficients["empathy", "Pr(>|t|)"]

info_warmth_b <- coef(warmth_process_model)["info"]
info_warmth_p <- summary(warmth_process_model)$coefficients["info", "Pr(>|t|)"]
empathy_warmth_b <- coef(warmth_process_model)["empathy"]
empathy_warmth_p <- summary(warmth_process_model)$coefficients["empathy", "Pr(>|t|)"]
```

Participants who found the chatbot more informative showed `r if(info_acc_p < 0.05) "significantly" else "marginally"` better accuracy improvement (*b* = `r sprintf("%.3f", info_acc_b)`, *p* `r if(info_acc_p < 0.001) "< .001" else paste("=", sprintf("%.3f", info_acc_p))`) and `r if(info_warmth_p < 0.05) "significantly" else "marginally"` greater warmth increases (*b* = `r sprintf("%.2f", info_warmth_b)`, *p* `r if(info_warmth_p < 0.001) "< .001" else paste("=", sprintf("%.3f", info_warmth_p))`). Bot empathy did not significantly predict accuracy change (*b* = `r sprintf("%.3f", empathy_acc_b)`, *p* `r if(empathy_acc_p < 0.001) "< .001" else paste("=", sprintf("%.3f", empathy_acc_p))`) or warmth change (*b* = `r sprintf("%.2f", empathy_warmth_b)`, *p* `r if(empathy_warmth_p < 0.001) "< .001" else paste("=", sprintf("%.3f", empathy_warmth_p))`).

```{r}
# Display models
modelsummary(
  list("Accuracy" = accuracy_process_model, "Warmth" = warmth_process_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  coef_map = coef_map_common,
  notes = "Note: Regressions control for pre-interaction values. * p<0.05, ** p<0.01, *** p<0.001"
)
```

Do perceptions of informativeness and empathy correlate with each other? Yes, but not strongly (r ~ .30). 

```{r}
dat_for_reg %>%
  ggplot(aes(x = empathy, y = info, color = learner_party)) +
  geom_jitter(alpha = 0.6, size = 2.5, width = 0.3, height = 0.3) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    title = "Relationship Between Bot Empathy and Informativeness",
    x = "Empathy Rating (1-5)",
    y = "Informativeness Rating (1-5)"
  ) +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

### Q5. Does engagement ("dose") matter for belief updating?

```{r engagement-descriptives}
# Descriptive statistics for engagement
engagement_summary <- dat %>%
  summarise(
    mean_turns = mean(user_turn_count, na.rm = TRUE),
    sd_turns = sd(user_turn_count, na.rm = TRUE),
    mean_words = mean(user_word_count, na.rm = TRUE),
    sd_words = sd(user_word_count, na.rm = TRUE)
  )

# Create change scores and log-transformed word count
# No +1 needed for log transform since min word count = 47
dat <- dat %>%
  mutate(
    accuracy_change = accuracy_post - accuracy_pre,  # Negative = improvement
    warmth_change = warmth_outgroup_post - warmth_outgroup_pre,
    log_word_count = log(user_word_count)
  )
```

We measured engagement as the number of words participants typed during the chat and tested whether greater engagement predicted larger changes in beliefs and warmth. 
Participants engaged in an average of `r sprintf("%.2f", engagement_summary$mean_turns)` conversation turns (*SD* = `r sprintf("%.2f", engagement_summary$sd_turns)`) and typed an average of `r sprintf("%.2f", engagement_summary$mean_words)` words (*SD* = `r sprintf("%.2f", engagement_summary$sd_words)`).

#### Does engagement predict belief accuracy improvement?

```{r engagement-models}
# Model: Engagement predicting accuracy and warmth change
m_accuracy_turns <- lm(accuracy_change ~ user_turn_count + accuracy_pre + learner_party,
                       data = dat)
m_accuracy_log_words <- lm(accuracy_change ~ log_word_count + accuracy_pre + learner_party,
                           data = dat)
m_warmth_turns <- lm(warmth_change ~ user_turn_count + warmth_outgroup_pre + learner_party,
                     data = dat)
m_warmth_log_words <- lm(warmth_change ~ log_word_count + warmth_outgroup_pre + learner_party,
                         data = dat)
```

Greater engagement—measured by turn count—was `r if(coef(summary(m_accuracy_turns))["user_turn_count", "Pr(>|t|)"] < 0.05) "significantly" else "not significantly"` associated with accuracy change (*b* = `r sprintf("%.4f", coef(m_accuracy_turns)["user_turn_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_accuracy_turns))["user_turn_count", "Pr(>|t|)"])`), and `r if(coef(summary(m_warmth_turns))["user_turn_count", "Pr(>|t|)"] < 0.05) "significantly" else "not significantly"` associated with warmth change (*b* = `r sprintf("%.4f", coef(m_warmth_turns)["user_turn_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_warmth_turns))["user_turn_count", "Pr(>|t|)"])`). Using log-transformed word count, the effect on accuracy was `r if(coef(summary(m_accuracy_log_words))["log_word_count", "Pr(>|t|)"] < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.4f", coef(m_accuracy_log_words)["log_word_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_accuracy_log_words))["log_word_count", "Pr(>|t|)"])`), and on warmth was `r if(coef(summary(m_warmth_log_words))["log_word_count", "Pr(>|t|)"] < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.4f", coef(m_warmth_log_words)["log_word_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_warmth_log_words))["log_word_count", "Pr(>|t|)"])`).

```{r}
# Consolidated table
modelsummary(
  list(
    "Turn Count" = m_accuracy_turns,
    "Log(Word Count)" = m_accuracy_log_words,
    "Turn Count" = m_warmth_turns,
    "Log(Word Count)" = m_warmth_log_words
  ),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  coef_map = coef_map_common
)  %>%
  group_tt(j = list("Accuracy" = 2:3, "Warmth" = 4:5))
```

```{r engagement-plots}
#| fig-width: 10
#| fig-height: 8

# Filter out outliers with over 75 turns
dat_filtered <- dat %>% filter(user_turn_count <= 75)

# Plots with turn count
p1 <- ggplot(dat_filtered, aes(x = user_turn_count, y = accuracy_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  stat_cor()+
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    x = "Turn Count",
    y = "Accuracy Change\n(Negative = Improvement)",
    title = "Turn Count and Accuracy Change"
  ) +
  theme_minimal()

p2 <- ggplot(dat_filtered, aes(x = user_turn_count, y = warmth_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  stat_cor()+
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    x = "Turn Count",
    y = "Warmth Change\n(Positive = Increase)",
    title = "Turn Count and Warmth Change"
  ) +
  theme_minimal()

# Plots with log word count
p3 <- ggplot(dat_filtered, aes(x = log_word_count, y = accuracy_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  stat_cor()+
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    x = "Log(Word Count)",
    y = "Accuracy Change\n(Negative = Improvement)",
    title = "Log(Word Count) and Accuracy Change"
  ) +
  theme_minimal()

p4 <- ggplot(dat_filtered, aes(x = log_word_count, y = warmth_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = TRUE) +
  stat_cor()+
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    x = "Log(Word Count)",
    y = "Warmth Change\n(Positive = Increase)",
    title = "Log(Word Count) and Warmth Change"
  ) +
  theme_minimal()

# Combine plots with single shared legend at bottom
(p1 + p2) / (p3 + p4) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")
```

### Q6. Does interacting with the chatbot improve applied judgment?

Participants wrote slogans for marketing energy-saving appliances to the political outgroup. I haven't touched this data yet, because we don't have a control condition or a baseline slogan to make a meaningful comparison to.

**DATA AVAILABLE**: Raw slogan text in variable `Q23` (n = `r sum(!is.na(dat$Q23))` responses).

**DATA NEEDED**:
1. Semantic similarity scores (compare to AI-generated responses to detect copying)
2. Quality ratings (human or LLM ratings of slogan fit to target outgroup)

### Q7. Does confidence track accuracy—or diverge from it?

We examine participants' metacognitive awareness by testing (1) whether confidence changes from pre to post, and (2) whether confidence changes track with actual accuracy improvements.

#### Does confidence change pre-to-post?

```{r confidence-model}
# Prepare confidence data in long format
confidence_long <- dat %>%
  select(ResponseId, learner_party, confidence_outgroup_pre, confidence_outgroup_post) %>%
  pivot_longer(cols = c(confidence_outgroup_pre, confidence_outgroup_post),
               names_to = "time", names_pattern = "confidence_outgroup_(pre|post)",
               values_to = "confidence") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

# Calculate summary statistics for plot
confidence_summary <- confidence_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_confidence = mean(confidence, na.rm = TRUE),
            se_confidence = sd(confidence, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")



# Mixed-effects models
confidence_model0 <- lmer(confidence ~ time + (1 | ResponseId), data = confidence_long)
confidence_model <- lmer(confidence ~ time * learner_party + (1 | ResponseId), data = confidence_long)

# Get simple effects for the interaction model
confidence_contrasts <- emmeans(confidence_model, ~ time | learner_party) %>%
  contrast("pairwise") %>%
  tidy()

# Extract values for inline reporting
conf_dr_est <- confidence_contrasts$estimate[1]  # D→R effect
conf_dr_p <- confidence_contrasts$p.value[1]
conf_rd_est <- confidence_contrasts$estimate[2]  # R→D effect
conf_rd_p <- confidence_contrasts$p.value[2]

# Format simple effects
conf_formatted <- confidence_contrasts %>%
  mutate(
    stars = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    ),
    formatted = sprintf("%.3f%s", estimate, stars),
    se_formatted = sprintf("(%.3f)", std.error)
  )

rows_confidence <- tibble(
  term = c("Time effect (D→R)", "", "Time effect (R→D)", ""),
  `Confidence (Main Effect)` = c("", "", "", ""),
  `Confidence (Interaction)` = c(conf_formatted$formatted[1], conf_formatted$se_formatted[1],
                                 conf_formatted$formatted[2], conf_formatted$se_formatted[2])
)
attr(rows_confidence, "position") <- c(1, 2, 3, 4)
```

Republicans learning about Democrats gained confidence after the interaction (*b* = `r sprintf("%.3f", conf_rd_est)`, *p* `r if(conf_rd_p < 0.001) "< .001" else paste("=", sprintf("%.3f", conf_rd_p))`), despite learning less than Democrats. Democrats' confidence did not significantly change (*b* = `r sprintf("%.3f", conf_dr_est)`, *p* `r if(conf_dr_p < 0.001) "< .001" else paste("=", sprintf("%.3f", conf_dr_p))`).

```{r}
# Confidence plot
ggplot(confidence_summary, aes(x = time, y = mean_confidence, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_confidence - se_confidence, ymax = mean_confidence + se_confidence), width = 0.1) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(title = "Confidence in Outgroup Judgments", x = "Time", y = "Mean Confidence (1-5)") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")

# Display models
modelsummary(
  list("Confidence (Main Effect)" = confidence_model0,
       "Confidence (Interaction)" = confidence_model),
  stars = TRUE,
  add_rows = rows_confidence,
  gof_map = c("nobs", "r.squared"),
  coef_map = coef_map_common,
  notes = "Note: Confidence rated on 1-5 scale. * p<0.05, ** p<0.01, *** p<0.001"
) %>%
  strip_tt(line = TRUE) %>%
  group_tt(i = list("Simple Effects by Political Affiliation" = 1, "Full Regression Results" = 5)) %>%
  style_tt(i = c(1, 6), bold = TRUE) %>%
  style_tt(i = c(14, 16), line = "b", line_color = "lightgray")
```

#### Correlation: Does confidence change track accuracy improvement?

```{r confidence-calibration, fig.width=8, fig.height=6}
# Compute change scores
calibration_dat <- dat_for_reg %>%
  mutate(
    confidence_change = confidence_outgroup_post - confidence_outgroup_pre,
    accuracy_change = accuracy_post - accuracy_pre  # Negative = improvement
  )

# Compute correlations by group
cor_overall <- cor.test(calibration_dat$confidence_change, calibration_dat$accuracy_change)
cor_dr <- cor.test(
  calibration_dat$confidence_change[calibration_dat$learner_party == "D→R"],
  calibration_dat$accuracy_change[calibration_dat$learner_party == "D→R"]
)
cor_rd <- cor.test(
  calibration_dat$confidence_change[calibration_dat$learner_party == "R→D"],
  calibration_dat$accuracy_change[calibration_dat$learner_party == "R→D"]
)
```

Overall, confidence change did not track with accuracy improvement (*r* = `r sprintf("%.3f", cor_overall$estimate)`, *p* `r if(cor_overall$p.value < 0.001) "< .001" else paste("=", sprintf("%.3f", cor_overall$p.value))`). For Democrats learning about Republicans, there was a `r if(cor_dr$p.value < 0.05) "significant positive" else "positive"` correlation between confidence change and accuracy change (*r* = `r sprintf("%.3f", cor_dr$estimate)`, *p* `r if(cor_dr$p.value < 0.001) "< .001" else paste("=", sprintf("%.3f", cor_dr$p.value))`), indicating that those who became less accurate gained more confidence. For Republicans learning about Democrats, confidence change did not correlate with accuracy change (*r* = `r sprintf("%.3f", cor_rd$estimate)`, *p* `r if(cor_rd$p.value < 0.001) "< .001" else paste("=", sprintf("%.3f", cor_rd$p.value))`).

```{r}
# Create scatter plot with correlation statistics
ggplot(calibration_dat, aes(x = confidence_change, y = accuracy_change, color = learner_party)) +
  geom_jitter(alpha = 0.6, size = 2.5, width = .2, height= 0) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    x = "Confidence Change (Post - Pre)",
    y = "Accuracy Change (Post - Pre)\nNegative = Improvement",
    title = "Confidence-Accuracy Calibration",
    subtitle = "Does confidence change track with accuracy improvement?",
    caption = "Note: Negative correlation would indicate increased confidence associated with improved accuracy"
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5)+
  geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.5)+
  annotate(geom = 'text', x = 2.5, y = -2.5, label= 'Rightfully\nmore confident', size = 3) +
  annotate(geom = 'text', x = -2.5, y = -2.5, label= 'Rightfully\nless confident', size = 3) +
  annotate(geom = 'text', x = 2.5, y = 2.5, label= 'Wrongly\nmore confident', size = 3) +
  annotate(geom = 'text', x = -2.5, y = 2.5, label= 'Wrongly\nless confident', size = 3) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    plot.caption = element_text(hjust = 0, size = 9, color = "gray40"),
    legend.position = "bottom"
  )
```


## Discussion

### Summary of Findings

Brief interactions with an AI chatbot representing a political outgroup improved accuracy of beliefs about that outgroup and increased warmth toward them. Participants became more accurate in estimating their political outgroup's environmental attitudes and reported warmer feelings toward the outgroup on a feeling thermometer. These effects were asymmetric: Democrats learning about Republicans showed greater accuracy improvements than Republicans learning about Democrats, though both groups increased warmth at similar rates.

Political extremism predicted greater baseline bias and lower baseline warmth but did not moderate the intervention's effectiveness. More and less extreme participants benefited equally from the interaction. Perceptions of the chatbot's informativeness predicted better outcomes, while perceived empathy did not. Greater engagement, measured by conversation length, showed mixed associations with belief updating.

Confidence changes did not track with accuracy improvements. Republicans learning about Democrats gained confidence despite smaller accuracy gains, while Democrats' confidence did not change. For Democrats, confidence increases were paradoxically associated with becoming less accurate, suggesting poor metacognitive calibration in this context.

### Implications for Marketing Practice

These findings suggest that AI-mediated interactions can serve as a scalable tool for reducing political misperceptions in consumer research. Marketers often struggle to understand ideologically diverse consumer segments, relying on stereotypes or costly focus groups. AI chatbots could provide an accessible method for gaining insight into outgroup consumer preferences and values.

This approach may be particularly valuable for marketing environmentally responsible products, where political divides can lead to misperceptions about consumer attitudes. Understanding that political outgroups may be more environmentally conscious than stereotypes suggest could inform more effective cross-partisan messaging strategies.

### Limitations

This study has several limitations that provide directions for future research.

**Domain specificity.** The environmental attitude domain may not generalize to other consumer preferences or policy areas. Environmental attitudes represent a domain where partisan divides exist but are not as stark as other politically charged topics. Future research should examine whether AI-mediated learning transfers to domains with deeper partisan disagreement, such as immigration, healthcare, or gun policy. The effectiveness of this intervention may vary depending on the perceived relevance of the attitude domain to partisan identity.

**Temporal dynamics.** This study examines only immediate post-interaction effects. The durability of accuracy improvements and warmth increases remains unknown. Research on intergroup contact suggests that initial attitude changes can decay over time, particularly without repeated exposure. Future studies should include delayed follow-up measurements to assess whether belief updates persist days, weeks, or months after the interaction. Understanding decay rates would inform practical recommendations about intervention frequency for sustained effects.

**AI representation versus human reality.** Participants interacted with an AI chatbot prompted to represent a political outgroup rather than actual outgroup members. While this approach offers scalability advantages, it raises questions about whether insights gained from AI interactions transfer to understanding real outgroup members. The chatbot was prompted to represent the outgroup but may not fully capture the diversity of views within each political group. Individual variation within partisan groups is substantial, and the AI's responses may reinforce stereotypes about group homogeneity even as they correct specific attitude misperceptions. Future research should examine whether learning from AI translates to more accurate perceptions of actual individuals and whether AI-mediated learning produces different outcomes than human-mediated contact.

**Comparison to alternative interventions.** This study does not compare the chatbot intervention to other approaches for reducing partisan misperceptions. Standard perspective-taking interventions have shown some effectiveness in reducing intergroup bias in the psychological literature. Information provision through simple fact sheets or Google searches might achieve similar accuracy improvements at lower cost. Interactions with digital twins based on actual individuals' response patterns could combine scalability with greater authenticity. Future research should directly compare these alternatives to determine the relative effectiveness and cost-efficiency of AI chatbots versus other scalable interventions for partisan debiasing.

## Appendix

### Summary table of regressions
```{r}
# Accuracy models panel
modelsummary(
  list(
    "Main Effect" = accuracy_model0,
    "Interaction" = accuracy_model,
    "Extremism" = accuracy_extremism_model,
    # "Baseline" = baseline_accuracy_extremism,
    "Information/Empathy" = accuracy_process_model,
    "Turns" = m_accuracy_turns,
    "Words" = m_accuracy_log_words
  ),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  coef_omit = "Intercept",
  statistic = NULL,
  coef_map = coef_map_common,
  notes = "Note: Models 1-3 are mixed effects with random intercepts. Models 4-6 are OLS. * p<0.05, ** p<0.01, *** p<0.001"
) %>%
  group_tt(j = list(
    "Pre-Post Change" = 2:3,
    "Extremism" = 4,
    "Mechanisms" = 5:7
  ))

# Warmth models panel
modelsummary(
  list(
    "Main Effect" = warmth_model0,
    "Interaction" = warmth_model,
    "Extremism" = warmth_extremism_model,
    "Information/Empathy" = warmth_process_model,
    "Turns" = m_warmth_turns,
    "Words" = m_warmth_log_words
  ),
  stars = TRUE,
  statistic = NULL,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  coef_omit = "Intercept",
  coef_map = coef_map_common,
  notes = "Note: Models 1-3 are mixed effects with random intercepts. Models 4-6 are OLS. * p<0.05, ** p<0.01, *** p<0.001"
) %>%
  group_tt(j = list(
    "Pre-Post Change" = 2:3,
    "Extremism" = 4,
    "Mechanisms" = 5:7
  ))
```

### Descriptive Statistics

```{r descriptives-actual-attitudes}
# Actual environmental attitudes by party
dat %>%
  group_by(participant_party) %>%
  summarise(
    mean_green = mean(green_own, na.rm = TRUE),
    sd_green = sd(green_own, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    participant_party = "Political Party",
    mean_green = "Mean Green Attitude",
    sd_green = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_green, sd_green), decimals = 2) %>%
  tab_header(
    title = "Actual Environmental Attitudes by Political Party",
    subtitle = "Self-reported green attitudes (1-5 scale)"
  )
```

```{r descriptives-accuracy}
# Accuracy by time and learner party
accuracy_long %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_error = mean(error, na.rm = TRUE),
    sd_error = sd(error, na.rm = TRUE),
    n = sum(!is.na(error)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_error = "Mean Error",
    sd_error = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_error, sd_error), decimals = 3) %>%
  tab_header(
    title = "Outgroup Belief Accuracy",
    subtitle = "Absolute error (lower = more accurate)"
  )
```

```{r descriptives-warmth}
# Warmth by time and learner party
warmth_long %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_warmth = mean(warmth, na.rm = TRUE),
    sd_warmth = sd(warmth, na.rm = TRUE),
    n = sum(!is.na(warmth)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_warmth = "Mean Warmth",
    sd_warmth = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_warmth, sd_warmth), decimals = 2) %>%
  tab_header(
    title = "Outgroup Warmth (Feeling Thermometer)",
    subtitle = "By learner party and time point (0-100 scale)"
  )
```

```{r descriptives-extremism}
# Political extremism by learner party
dat %>%
  group_by(learner_party) %>%
  summarise(
    mean_extremism = mean(political_extremism, na.rm = TRUE),
    sd_extremism = sd(political_extremism, na.rm = TRUE),
    min_extremism = min(political_extremism, na.rm = TRUE),
    max_extremism = max(political_extremism, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    mean_extremism = "Mean",
    sd_extremism = "SD",
    min_extremism = "Min",
    max_extremism = "Max"
  ) %>%
  fmt_number(columns = c(mean_extremism, sd_extremism, min_extremism, max_extremism), decimals = 2) %>%
  tab_header(
    title = "Political Extremism by Learner Party",
    subtitle = "Distance from political center (0-50 scale)"
  )
```

```{r descriptives-bot-perceptions}
# Bot perceptions by learner party
dat %>%
  select(learner_party, info, empathy) %>%
  pivot_longer(cols = c(info, empathy), names_to = "measure", values_to = "rating") %>%
  mutate(measure = case_when(
    measure == "info" ~ "Informativeness",
    measure == "empathy" ~ "Empathy",
    TRUE ~ measure
  )) %>%
  group_by(learner_party, measure) %>%
  summarise(
    mean_rating = mean(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    n = sum(!is.na(rating)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    measure = "Measure",
    mean_rating = "Mean Rating",
    sd_rating = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_rating, sd_rating), decimals = 2) %>%
  tab_header(
    title = "Bot Perception Ratings",
    subtitle = "By learner party (1-5 scale)"
  )
```

```{r descriptives-confidence}
# Confidence by time and learner party
dat %>%
  select(ResponseId, learner_party, confidence_outgroup_pre, confidence_outgroup_post) %>%
  pivot_longer(cols = c(confidence_outgroup_pre, confidence_outgroup_post),
               names_to = "time", names_pattern = "confidence_outgroup_(pre|post)",
               values_to = "confidence") %>%
  mutate(time = factor(time, levels = c("pre", "post"))) %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_confidence = mean(confidence, na.rm = TRUE),
    sd_confidence = sd(confidence, na.rm = TRUE),
    n = sum(!is.na(confidence)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_confidence = "Mean Confidence",
    sd_confidence = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_confidence, sd_confidence), decimals = 2) %>%
  tab_header(
    title = "Confidence in Outgroup Judgments",
    subtitle = "By learner party and time point (1-5 scale)"
  )
```

### Robustness Checks

#### Warmth Difference Score

Following common practice in the affective polarization literature, we examine warmth using a difference score (outgroup - ingroup). Effects replicate what is reported on the main text.

```{r warmth-difference}
# Prepare warmth difference data
warmth_diff_long <- dat %>%
  select(ResponseId, learner_party, warmth_diff_pre, warmth_diff_post) %>%
  pivot_longer(cols = c(warmth_diff_pre, warmth_diff_post), names_to = "time",
               names_pattern = "warmth_diff_(pre|post)", values_to = "warmth_diff") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

# Mixed-effects model
warmth_diff_model <- lmer(warmth_diff ~ time * learner_party + (1 | ResponseId), data = warmth_diff_long)

# Get simple effects
warmth_diff_contrasts <- emmeans(warmth_diff_model, ~ time | learner_party) %>%
  contrast("pairwise") %>%
  tidy()

# Format simple effects
warmth_diff_formatted <- warmth_diff_contrasts %>%
  mutate(
    stars = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    ),
    formatted = sprintf("%.3f%s", estimate, stars),
    se_formatted = sprintf("(%.3f)", std.error)
  )

rows_warmth_diff <- tibble(
  term = c("Time effect (D→R)", "", "Time effect (R→D)", ""),
  `Warmth Difference` = c(warmth_diff_formatted$formatted[1], warmth_diff_formatted$se_formatted[1],
                          warmth_diff_formatted$formatted[2], warmth_diff_formatted$se_formatted[2])
)
attr(rows_warmth_diff, "position") <- c(1, 2, 3, 4)

# Display model
modelsummary(
  list("Warmth Difference" = warmth_diff_model),
  stars = TRUE,
  add_rows = rows_warmth_diff,
  gof_map = c("nobs", "r.squared"),
  coef_map = coef_map_common,
  notes = "Note: Warmth difference = outgroup - ingroup. Positive values indicate reduced polarization. * p<0.05, ** p<0.01, *** p<0.001"
) %>%
  strip_tt(line = TRUE) %>%
  group_tt(i = list("Simple Effects by Political Affiliation" = 1, "Full Regression Results" = 5)) %>%
  style_tt(i = c(1, 6), bold = TRUE) %>%
  style_tt(i = c(12, 14), line = "b", line_color = "lightgray")
```

### Extreme Cases Analysis

To understand what characterizes successful versus unsuccessful learning, we examined participants who showed the most and least improvement in accuracy about their political outgroup.

```{r extreme-cases-analysis}
# Calculate accuracy improvement (negative = improvement)
extreme_cases <- dat %>%
  mutate(accuracy_improvement = accuracy_pre - accuracy_post) %>%
  group_by(learner_party) %>%
  arrange(desc(accuracy_improvement)) %>%
  slice(c(1, n())) %>%
  ungroup() %>%
  mutate(
    case_type = rep(c("Most Improved", "Least Improved"), 2)
  ) %>%
  select(ResponseId, learner_party, case_type,
         accuracy_pre, accuracy_post, accuracy_improvement,
         user_word_count, user_turn_count, Q23)

# Display summary table
extreme_cases %>%
  select(learner_party, case_type, accuracy_improvement, user_word_count, user_turn_count) %>%
  gt() %>%
  cols_label(
    learner_party = "Group",
    case_type = "Case",
    accuracy_improvement = "Accuracy Improvement",
    user_word_count = "Word Count",
    user_turn_count = "Turn Count"
  ) %>%
  fmt_number(columns = accuracy_improvement, decimals = 3) %>%
  fmt_number(columns = c(user_word_count, user_turn_count), decimals = 0) %>%
  tab_header(
    title = "Extreme Cases: Most vs. Least Improved",
    subtitle = "Accuracy improvement by learner party"
  ) %>%
  tab_footnote(
    footnote = "Positive values indicate improvement (reduced error)",
    locations = cells_column_labels(columns = accuracy_improvement)
  )
```

#### Marketing Messages from Extreme Cases

Participants wrote marketing slogans for energy-saving appliances targeted at their political outgroup. The messages reveal stark differences between successful and unsuccessful learners.

**Democrats Learning About Republicans (D→R)**

*Most Improved* (accuracy improvement = 2.843):
> "Energy-saving Appliances, Helps Make America Great!"

This message uses patriotic language that bridges partisan values. The participant engaged deeply on economic issues and found genuine common ground.

*Least Improved* (accuracy worsened by 1.333):
> "made for independence 'lower your costs, stay in control'."

This message shows confused framing about independence and control. The participant's conversation remained surface-level and distracted.

**Republicans Learning About Democrats (R→D)**

*Most Improved* (accuracy improvement = 3.000):
> "energy saving appliances . save energy and our planet"

This message authentically reflects Democratic environmental values with simple, accessible language. The participant's conversation explored multiple policy areas comprehensively.

*Least Improved* (accuracy worsened by 2.167):
> "Come spend 50% more on less practical appliances since that's what you claim to do and support the business. But I know you won't because just like every Republican said its not financially plausible and your actions only prove the Republicans point."

This openly hostile message reinforces stereotypes rather than bridging divides. The participant challenged the chatbot's authenticity throughout and remained adversarial.

#### Patterns in Successful vs. Unsuccessful Learning

```{r extreme-cases-engagement}
# Compare engagement between successful and unsuccessful learners
engagement_comparison <- extreme_cases %>%
  mutate(
    success = ifelse(accuracy_improvement > 0, "Improved", "Worsened")
  ) %>%
  group_by(success) %>%
  summarise(
    mean_word_count = mean(user_word_count, na.rm = TRUE),
    mean_turn_count = mean(user_turn_count, na.rm = TRUE),
    .groups = "drop"
  )

engagement_comparison %>%
  gt() %>%
  cols_label(
    success = "Outcome",
    mean_word_count = "Mean Word Count",
    mean_turn_count = "Mean Turn Count"
  ) %>%
  fmt_number(columns = c(mean_word_count, mean_turn_count), decimals = 1) %>%
  tab_header(
    title = "Engagement by Learning Outcome",
    subtitle = "Comparing extreme cases"
  )
```

The qualitative analysis of conversations (full transcripts available in data/processed/conversations/) reveals distinct patterns:

**Successful learners**:

- Approached conversations with genuine curiosity
- Explored substantive policy topics in depth
- Found common ground on shared concerns
- Asked respectful, probing questions
- Created simple, bridge-building marketing messages

**Unsuccessful learners**:

- Remained skeptical or hostile throughout
- Brought external "evidence" to confirm preconceptions
- Challenged the chatbot's authenticity
- Stayed in adversarial mode
- Created divisive or sarcastic marketing messages

These patterns suggest that genuine engagement is crucial for learning across partisan lines. Participants who used the conversation to confirm existing biases actually became less accurate, while those who approached it with openness showed dramatic improvements.

### Full Conversation Transcripts

The following sections present the complete conversations for each extreme case, illustrating the qualitative differences between successful and unsuccessful learning.

#### D→R Most Improved: R_3smKFSFIo8Nlgir

**Accuracy improvement**: 2.843 (from 2.921 to 0.079)
**Marketing message**: "Energy-saving Appliances, Helps Make America Great!"

```{r conversation-dr-most, results='asis'}
convo <- fromJSON("../data/processed/conversations/R_3smKFSFIo8Nlgir.json")

cat("\n")
for (i in 1:nrow(convo)) {
  msg <- convo[i, ]
  role_display <- ifelse(msg$role == "user", "**PARTICIPANT**", "**CHATBOT**")
  cat(sprintf("%s\n\n", role_display))
  cat(sprintf("%s\n\n", msg$content))
  if (i < nrow(convo)) cat("---\n\n")
}
```

**Analysis**: This conversation shows deep engagement on economic issues. The participant found genuine common ground on concerns about taxes, regulations, and job stability. The chatbot explored practical implications of reduced government intervention, and the participant asked probing questions about implementation. This substantive exchange led to dramatically improved accuracy and a patriotic marketing message that bridges partisan values.

#### D→R Least Improved: R_7roKHi99S0lQCJq

**Accuracy change**: -1.333 (worsened from 1.088 to 2.421)
**Marketing message**: "made for independence 'lower your costs, stay in control'."

```{r conversation-dr-least, results='asis'}
convo <- fromJSON("../data/processed/conversations/R_7roKHi99S0lQCJq.json")

cat("\n")
for (i in 1:nrow(convo)) {
  msg <- convo[i, ]
  role_display <- ifelse(msg$role == "user", "**PARTICIPANT**", "**CHATBOT**")
  cat(sprintf("%s\n\n", role_display))
  cat(sprintf("%s\n\n", msg$content))
  if (i < nrow(convo)) cat("---\n\n")
}
```

**Analysis**: This participant appeared distracted (mentioning grading quizzes) and the conversation remained superficial. While practical topics were discussed (appliances, thermostats), the exchange never went deep enough to challenge preconceptions. The participant's attention was divided, and they didn't engage with substantive policy questions. The marketing message reflects this confused engagement.

#### R→D Most Improved: R_7rne5ptEvs5r7Il

**Accuracy improvement**: 3.000 (from 3.251 to 0.251)
**Marketing message**: "energy saving appliances . save energy and our planet"

```{r conversation-rd-most, results='asis'}
convo <- fromJSON("../data/processed/conversations/R_7rne5ptEvs5r7Il.json")

cat("\n")
for (i in 1:nrow(convo)) {
  msg <- convo[i, ]
  role_display <- ifelse(msg$role == "user", "**PARTICIPANT**", "**CHATBOT**")
  cat(sprintf("%s\n\n", role_display))
  cat(sprintf("%s\n\n", msg$content))
  if (i < nrow(convo)) cat("---\n\n")
}
```

**Analysis**: This wide-ranging conversation explored Democratic values comprehensively—environment, healthcare, social justice, immigration. The participant asked about core beliefs and policy positions, maintaining a respectful tone even when disagreeing. The chatbot provided detailed explanations of Democratic perspectives. This genuine exploration led to dramatic accuracy improvement and an authentic environmental message.

#### R→D Least Improved: R_39bB9XiMhyFaHnj

**Accuracy change**: -2.167 (worsened from 0.751 to 2.918)
**Marketing message**: "Come spend 50% more on less practical appliances since that's what you claim to do and support the business. But I know you won't because just like every Republican said its not financially plausible and your actions only prove the Republicans point."

```{r conversation-rd-least, results='asis'}
convo <- fromJSON("../data/processed/conversations/R_39bB9XiMhyFaHnj.json")

cat("\n")
for (i in 1:nrow(convo)) {
  msg <- convo[i, ]
  role_display <- ifelse(msg$role == "user", "**PARTICIPANT**", "**CHATBOT**")
  cat(sprintf("%s\n\n", role_display))
  cat(sprintf("%s\n\n", msg$content))
  if (i < nrow(convo)) cat("---\n\n")
}
```

**Analysis**: This conversation was hostile from the start. The participant challenged the chatbot's authenticity, cited external "evidence" (a BBC study) to prove Democrats are hypocrites, and remained adversarial throughout. Rather than exploring Democratic perspectives, the participant used the conversation to confirm negative stereotypes. The chatbot tried to acknowledge concerns and find common ground, but the participant rejected these attempts. This confirmation bias approach led to worsened accuracy and an openly hostile marketing message.

---

### Data Availability

Raw data: [data/raw/qualtrics.parquet](../data/raw/qualtrics.parquet)

Cleaned data: [data/processed/cleaned_data.parquet](../data/processed/cleaned_data.parquet)

Analysis data (minimal, for publication): [data/processed/analysis_data.parquet](../data/processed/analysis_data.parquet)

Conversations: [data/processed/conversations/](../data/processed/conversations/)

### Code Availability

Data cleaning: [src/r/clean_data.R](../src/r/clean_data.R)

Analysis dataset creation: [src/r/create_analysis_data.R](../src/r/create_analysis_data.R)

Conversation download: [src/python/download_conversations.py](../src/python/download_conversations.py)

Extreme cases analysis: [src/r/analyze_extreme_cases.R](../src/r/analyze_extreme_cases.R)

### Pre-Registration

This study was pre-registered prior to data collection. See [docs/pre-registration.md](../docs/pre-registration.md) for complete details including hypotheses, measures, sample size justification, and planned analyses.

### Session Information

```{r session-info}
sessionInfo()
```
