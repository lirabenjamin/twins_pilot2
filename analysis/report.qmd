---
title: "Learning from Twins: Can marketers learn about consumers across the political divide by interacting with AI"
author: "Benjamin Lira"
date: today
format:
  html: default
  pdf: default
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
library(tidyverse)
library(arrow)
library(lme4)
library(lmerTest)
library(modelsummary)
library(gt)
library(ggplot2)

# Load cleaned data
dat <- read_parquet("../output/cleaned_data.parquet")
```

## Overview

Political polarization creates challenges for marketers who must communicate effectively with ideologically diverse consumers. Misperceptions about political outgroups are widespread, with partisans often holding exaggerated and inaccurate views of those across the political divide. These misperceptions can lead to ineffective marketing strategies when firms attempt to appeal to broad consumer bases. This study tests whether interacting with an AI chatbot prompted to represent a political outgroup can improve marketers' understanding of that outgroup and reduce affective polarization.

### Hypotheses

We hypothesized that after interacting with an AI chatbot representing their political outgroup, participants would:

1. **Report more accurate beliefs about the outgroup's attitudes** toward environmentally responsible consumption (Primary Outcome 1).
2. **Feel warmer toward the political outgroup** (Primary Outcome 2).

## Data

### Data Collection

Data were collected via Qualtrics from `r nrow(dat)` participants. Participants self-reported their political orientation on a 0-100 slider scale, where values below 50 indicate Democratic leaning and values 50 and above indicate Republican leaning.

```{r participant-breakdown}
dat %>%
  count(learner_party) %>%
  gt() %>%
  cols_label(learner_party = "Learner Party", n = "N") %>%
  tab_header(title = "Sample Composition")
```

### Measures

**Primary Outcomes**

- **Belief accuracy**: Absolute difference between participants' estimates of outgroup green attitudes and actual outgroup means (lower = more accurate)
- **Outgroup warmth**: Feeling thermometer (0-100 scale) toward the political outgroup

**Secondary Outcomes**

- Confidence in outgroup judgments (5-point scale)
- Bot informativeness and empathy ratings (5-point scale)

### Pre-Registered Analyses

For each primary outcome, we estimated mixed-effects models of the form:

$$y \sim \text{time} \times \text{learner\_party} + (1 | \text{id})$$

where `time` indexes pre- versus post-interaction measurement and `learner_party` indicates D→R versus R→D learning direction.

## Results

```{r prepare-long-data}
# Prepare long format datasets
accuracy_long <- dat %>%
  select(ResponseId, learner_party, accuracy_pre, accuracy_post) %>%
  pivot_longer(cols = c(accuracy_pre, accuracy_post), names_to = "time",
               names_pattern = "accuracy_(pre|post)", values_to = "error") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

warmth_long <- dat %>%
  select(ResponseId, learner_party, warmth_outgroup_pre, warmth_outgroup_post) %>%
  pivot_longer(cols = c(warmth_outgroup_pre, warmth_outgroup_post), names_to = "time",
               names_pattern = "warmth_outgroup_(pre|post)", values_to = "warmth") %>%
  mutate(time = factor(time, levels = c("pre", "post")))
```

### Q1. Do people update their beliefs after interacting with the chatbot?

We examine whether participants changed their beliefs about the outgroup's environmental attitudes from pre- to post-interaction, analyzing both accuracy and warmth.

```{r q1-data-prep}
# Calculate summary statistics for plots
accuracy_summary <- accuracy_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_error = mean(error, na.rm = TRUE),
            se_error = sd(error, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")

warmth_summary <- warmth_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_warmth = mean(warmth, na.rm = TRUE),
            se_warmth = sd(warmth, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")
```

```{r q1-plots, fig.width=10, fig.height=4}
#| layout-ncol: 2

# Accuracy plot
ggplot(accuracy_summary, aes(x = time, y = mean_error, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_error - se_error, ymax = mean_error + se_error), width = 0.1) +
  labs(title = "Belief Accuracy", x = "Time", y = "Mean Absolute Error", color = "Learner Party") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")

# Warmth plot
ggplot(warmth_summary, aes(x = time, y = mean_warmth, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_warmth - se_warmth, ymax = mean_warmth + se_warmth), width = 0.1) +
  labs(title = "Outgroup Warmth", x = "Time", y = "Mean Warmth", color = "Learner Party") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

```{r q1-models}
# Estimate mixed-effects models
accuracy_model0 <- lmer(error ~ time  + (1 | ResponseId), data = accuracy_long)
warmth_model0 <- lmer(warmth ~ time  + (1 | ResponseId), data = warmth_long)

accuracy_model <- lmer(error ~ time * learner_party + (1 | ResponseId), data = accuracy_long)
warmth_model <- lmer(warmth ~ time * learner_party + (1 | ResponseId), data = warmth_long)

# Display models side by side
modelsummary(
  list(
    "Accuracy" = accuracy_model0, 
    "Warmth" = warmth_model0),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Accuracy is absolute error (lower = more accurate). * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q2. Is belief updating symmetric across political groups?

The primary analyses above test whether Democrats and Republicans show different patterns of belief updating. The key test is the `time × learner_party` interaction in the mixed-effects models. A significant interaction would indicate asymmetric updating across groups.

```{r}
# Display models side by side
modelsummary(
  list(
    "Accuracy" = accuracy_model, 
    "Warmth" = warmth_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Accuracy is absolute error (lower = more accurate). * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q3. Does political extremity predict how much people update?

We explore whether participants' political extremism (distance from the political center) moderates the treatment effect.

```{r extremism-models}
# Add extremism to long data
accuracy_long_ext <- accuracy_long %>%
  left_join(dat %>% select(ResponseId, political_extremism), by = "ResponseId")

warmth_long_ext <- warmth_long %>%
  left_join(dat %>% select(ResponseId, political_extremism), by = "ResponseId")

# Models with extremism interaction
accuracy_extremism_model <- lmer(
  error ~ time * learner_party * political_extremism + (1 | ResponseId),
  data = accuracy_long_ext
)

warmth_extremism_model <- lmer(
  warmth ~ time * learner_party * political_extremism + (1 | ResponseId),
  data = warmth_long_ext
)

# Display models
modelsummary(
  list("Accuracy" = accuracy_extremism_model, "Warmth" = warmth_extremism_model),
  stars = TRUE,
  coef_omit = "Intercept",
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Three-way interaction tests whether extremism moderates differential updating. * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q4. Is belief updating associated with how the chatbot is perceived?

We examine whether participants who found the chatbot more informative or empathic showed greater belief updating, controlling for pre-interaction values.

```{r process-models}
# Prepare data for regressions
dat_for_reg <- dat %>%
  filter(!is.na(accuracy_pre), !is.na(accuracy_post),
         !is.na(warmth_outgroup_pre), !is.na(warmth_outgroup_post),
         !is.na(info), !is.na(empathy))

# Process measure regressions
accuracy_process_model <- lm(accuracy_post ~ accuracy_pre + info + empathy, data = dat_for_reg)
warmth_process_model <- lm(warmth_outgroup_post ~ warmth_outgroup_pre + info + empathy, data = dat_for_reg)

# Display models
modelsummary(
  list("Accuracy" = accuracy_process_model, "Warmth" = warmth_process_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  notes = "Note: Regressions control for pre-interaction values. * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q5. Does engagement ("dose") matter for belief updating?

**DATA NEEDED**: The pre-registration specified examining engagement operationalized as the number of words typed by participants during the chat. This variable is not currently available in the dataset.

**Planned analysis**: When word count data becomes available:
```
accuracy_post ~ accuracy_pre + word_count
warmth_post ~ warmth_pre + word_count
```

### Q6. Does interacting with the chatbot improve applied judgment?

Participants wrote slogans for marketing energy-saving appliances to the political outgroup.

**DATA AVAILABLE**: Raw slogan text in variable `Q23` (n = `r sum(!is.na(dat$Q23))` responses).

**DATA NEEDED**:
1. Semantic similarity scores (compare to AI-generated responses to detect copying)
2. Quality ratings (human or LLM ratings of slogan fit to target outgroup)

### Q7. Does confidence track accuracy—or diverge from it?

We examine participants' metacognitive awareness by testing whether confidence ratings track with actual accuracy.

```{r confidence-calibration}
# Compute change scores
calibration_dat <- dat_for_reg %>%
  mutate(
    confidence_change = confidence_outgroup_post - confidence_outgroup_pre,
    accuracy_change = accuracy_post - accuracy_pre  # Negative = improvement
  )

# Correlation
conf_acc_cor <- cor.test(calibration_dat$confidence_change,
                         calibration_dat$accuracy_change,
                         use = "complete.obs")

# Create summary table
tibble(
  Measure = c("Correlation", "95% CI Lower", "95% CI Upper", "p-value", "N"),
  Value = c(conf_acc_cor$estimate, conf_acc_cor$conf.int[1], conf_acc_cor$conf.int[2],
            conf_acc_cor$p.value,
            sum(complete.cases(calibration_dat[c("confidence_change", "accuracy_change")])))
) %>%
  gt() %>%
  fmt_number(columns = Value, rows = 1:3, decimals = 3) %>%
  fmt_number(columns = Value, rows = 4, decimals = 4) %>%
  fmt_number(columns = Value, rows = 5, decimals = 0) %>%
  tab_header(title = "Confidence-Accuracy Calibration",
             subtitle = "Correlation between confidence change and accuracy change") %>%
  tab_footnote(
    footnote = "Negative correlation would indicate that increased confidence is associated with improved accuracy (reduced error).",
    locations = cells_body(columns = Measure, rows = 1)
  )
```

### Robustness Checks

#### Warmth Difference Score

Following common practice in the affective polarization literature, we examine warmth using a difference score (outgroup - ingroup).

```{r warmth-difference}
# Prepare warmth difference data
warmth_diff_long <- dat %>%
  select(ResponseId, learner_party, warmth_diff_pre, warmth_diff_post) %>%
  pivot_longer(cols = c(warmth_diff_pre, warmth_diff_post), names_to = "time",
               names_pattern = "warmth_diff_(pre|post)", values_to = "warmth_diff") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

# Mixed-effects model
warmth_diff_model <- lmer(warmth_diff ~ time * learner_party + (1 | ResponseId), data = warmth_diff_long)

# Display model
modelsummary(
  list("Warmth Difference" = warmth_diff_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Warmth difference = outgroup - ingroup. Positive time coefficient indicates reduced polarization. * p<0.05, ** p<0.01, *** p<0.001"
)
```

## Discussion

### Summary of Findings

This pilot study tested whether interacting with an AI chatbot representing a political outgroup could improve participants' understanding of and warmth toward that outgroup. Using a within-subjects pre-post design, we examined changes in outgroup belief accuracy and outgroup warmth following an AI-mediated interaction.

### Primary Hypotheses

**Hypothesis 1: Outgroup Belief Accuracy**

We hypothesized that participants would report more accurate beliefs about the outgroup's environmental attitudes after interacting with the AI chatbot. Accuracy was operationalized as the absolute difference between participants' estimates and the outgroup's actual mean green attitudes. The time coefficient in the mixed-effects model indicates whether accuracy improved (error decreased) from pre to post, while the interaction term tests whether this change differed between Democrat and Republican learners.

**Hypothesis 2: Outgroup Warmth**

We hypothesized that participants would feel warmer toward the political outgroup after the interaction. The time coefficient indicates whether warmth increased from pre to post, while the interaction term tests whether Democrats and Republicans showed different patterns of change.

### Exploratory Findings

Secondary analyses examined confidence in outgroup judgments and perceptions of the bot's informativeness and empathy. Confidence ratings provide insight into participants' metacognitive awareness of their knowledge about the outgroup. Bot perception ratings help illuminate potential mechanisms—if participants found the bot informative and empathic, this may mediate changes in accuracy and warmth.

### Implications for Marketing Practice

If the hypothesized effects are supported, this research suggests that AI-mediated interactions can serve as a scalable tool for reducing political misperceptions in consumer research. Marketers often struggle to understand ideologically diverse consumer segments, relying on stereotypes or costly focus groups. AI chatbots could provide an accessible method for gaining insight into outgroup consumer preferences and values.

This approach may be particularly valuable for marketing environmentally responsible products, where political divides can lead to misperceptions about consumer attitudes. Understanding that political outgroups may be more environmentally conscious than stereotypes suggest could inform more effective cross-partisan messaging strategies.

### Limitations

Several limitations should be noted. The pilot sample consists primarily of test and preview responses, limiting statistical power and generalizability. The environmental attitude domain may not generalize to other consumer preferences. Belief accuracy depends on having adequate sample sizes within each political group to compute reliable actual outgroup means. The study examines only immediate post-interaction effects; durability of any changes remains unknown.

Additionally, participants interacted with an AI chatbot rather than actual outgroup members. While this approach offers scalability advantages, it raises questions about whether insights gained from AI interactions transfer to understanding real outgroup members. The chatbot was prompted to represent the outgroup but may not fully capture the diversity of views within each political group.

### Next Steps

The full study will recruit N = 500 participants from a representative sample. Key priorities include examining whether bot informativeness and empathy mediate changes in warmth and accuracy, analyzing participant-generated marketing slogans for energy-saving appliances, and testing for heterogeneous effects by political extremity and prior outgroup attitudes. Exploratory analyses will examine engagement (words typed during chat) as a predictor of outcomes.

Future research should examine the durability of effects over time, test generalizability to other product categories and consumer attitudes beyond environmental responsibility, and compare AI-mediated learning to alternative interventions such as reading testimonials from outgroup members or interacting with human outgroup representatives.

## Appendix

### Descriptive Statistics

```{r descriptives-actual-attitudes}
# Actual environmental attitudes by party
dat %>%
  group_by(participant_party) %>%
  summarise(
    mean_green = mean(green_own, na.rm = TRUE),
    sd_green = sd(green_own, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    participant_party = "Political Party",
    mean_green = "Mean Green Attitude",
    sd_green = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_green, sd_green), decimals = 2) %>%
  tab_header(
    title = "Actual Environmental Attitudes by Political Party",
    subtitle = "Self-reported green attitudes (1-5 scale)"
  )
```

```{r descriptives-accuracy}
# Accuracy by time and learner party
accuracy_long %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_error = mean(error, na.rm = TRUE),
    sd_error = sd(error, na.rm = TRUE),
    n = sum(!is.na(error)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_error = "Mean Error",
    sd_error = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_error, sd_error), decimals = 3) %>%
  tab_header(
    title = "Outgroup Belief Accuracy",
    subtitle = "Absolute error (lower = more accurate)"
  )
```

```{r descriptives-warmth}
# Warmth by time and learner party
warmth_long %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_warmth = mean(warmth, na.rm = TRUE),
    sd_warmth = sd(warmth, na.rm = TRUE),
    n = sum(!is.na(warmth)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_warmth = "Mean Warmth",
    sd_warmth = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_warmth, sd_warmth), decimals = 2) %>%
  tab_header(
    title = "Outgroup Warmth (Feeling Thermometer)",
    subtitle = "By learner party and time point (0-100 scale)"
  )
```

```{r descriptives-extremism}
# Political extremism by learner party
dat %>%
  group_by(learner_party) %>%
  summarise(
    mean_extremism = mean(political_extremism, na.rm = TRUE),
    sd_extremism = sd(political_extremism, na.rm = TRUE),
    min_extremism = min(political_extremism, na.rm = TRUE),
    max_extremism = max(political_extremism, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    mean_extremism = "Mean",
    sd_extremism = "SD",
    min_extremism = "Min",
    max_extremism = "Max"
  ) %>%
  fmt_number(columns = c(mean_extremism, sd_extremism, min_extremism, max_extremism), decimals = 2) %>%
  tab_header(
    title = "Political Extremism by Learner Party",
    subtitle = "Distance from political center (0-50 scale)"
  )
```

```{r descriptives-bot-perceptions}
# Bot perceptions by learner party
dat %>%
  select(learner_party, info, empathy) %>%
  pivot_longer(cols = c(info, empathy), names_to = "measure", values_to = "rating") %>%
  mutate(measure = case_when(
    measure == "info" ~ "Informativeness",
    measure == "empathy" ~ "Empathy",
    TRUE ~ measure
  )) %>%
  group_by(learner_party, measure) %>%
  summarise(
    mean_rating = mean(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    n = sum(!is.na(rating)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    measure = "Measure",
    mean_rating = "Mean Rating",
    sd_rating = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_rating, sd_rating), decimals = 2) %>%
  tab_header(
    title = "Bot Perception Ratings",
    subtitle = "By learner party (1-5 scale)"
  )
```

```{r descriptives-confidence}
# Confidence by time and learner party
dat %>%
  select(ResponseId, learner_party, confidence_outgroup_pre, confidence_outgroup_post) %>%
  pivot_longer(cols = c(confidence_outgroup_pre, confidence_outgroup_post),
               names_to = "time", names_pattern = "confidence_outgroup_(pre|post)",
               values_to = "confidence") %>%
  mutate(time = factor(time, levels = c("pre", "post"))) %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_confidence = mean(confidence, na.rm = TRUE),
    sd_confidence = sd(confidence, na.rm = TRUE),
    n = sum(!is.na(confidence)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_confidence = "Mean Confidence",
    sd_confidence = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_confidence, sd_confidence), decimals = 2) %>%
  tab_header(
    title = "Confidence in Outgroup Judgments",
    subtitle = "By learner party and time point (1-5 scale)"
  )
```

### Data Availability

Raw data: [data/raw/qualtrics.parquet](../data/raw/qualtrics.parquet)

Cleaned data: [output/cleaned_data.parquet](../output/cleaned_data.parquet)

### Code Availability

Data cleaning script: [src/clean_data.R](../src/clean_data.R)

### Pre-Registration

This study was pre-registered prior to data collection. See [docs/pre-registration.md](../docs/pre-registration.md) for complete details including hypotheses, measures, sample size justification, and planned analyses.

### Session Information

```{r session-info}
sessionInfo()
```
