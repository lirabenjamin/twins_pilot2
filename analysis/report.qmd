---
title: "Learning from Twins: Can marketers learn about consumers across the political divide by interacting with AI"
author: "Benjamin Lira"
date: today
format:
  html: default
  pdf: default
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
library(tidyverse)
library(arrow)
library(lme4)
library(lmerTest)
library(modelsummary)
library(gt)
library(ggplot2)
library(ggpubr)


# Load cleaned data
dat <- read_parquet("../data/processed/cleaned_data.parquet")

# Define consistent color scheme: Democrats = blue, Republicans = red
party_colors <- c("Democrat" = "#0015BC", "Republican" = "#E81B23")

# Define learner party colors (D→R = Democrat learning about Republicans, R→D = Republican learning about Democrats)
learner_party_colors <- c("D→R" = "#0015BC", "R→D" = "#E81B23")
```

## Overview

Political polarization creates challenges for marketers who must communicate effectively with ideologically diverse consumers. Misperceptions about political outgroups are widespread, with partisans often holding exaggerated and inaccurate views of those across the political divide. These misperceptions can lead to ineffective marketing strategies when firms attempt to appeal to broad consumer bases. This study tests whether interacting with an AI chatbot prompted to represent a political outgroup can improve marketers' understanding of that outgroup and reduce affective polarization.

### Hypotheses

We hypothesized that after interacting with an AI chatbot representing their political outgroup, participants would:

1. **Report more accurate beliefs about the outgroup's attitudes** toward environmentally responsible consumption (Primary Outcome 1).
2. **Feel warmer toward the political outgroup** (Primary Outcome 2).

## Data

### Data Collection

Data were collected via Qualtrics from `r nrow(dat)` participants. Participants self-reported their political orientation on a 0-100 slider scale, where values below 50 indicate Democratic leaning and values 50 and above indicate Republican leaning.

```{r participant-breakdown}
dat %>%
  count(learner_party) %>%
  gt() %>%
  cols_label(learner_party = "Learner Party", n = "N") %>%
  tab_header(title = "Sample Composition")
```

### Measures

**Primary Outcomes**

- **Belief accuracy**: Absolute difference between participants' estimates of outgroup green attitudes and actual outgroup means (lower = more accurate)
- **Outgroup warmth**: Feeling thermometer (0-100 scale) toward the political outgroup

**Secondary Outcomes**

- Confidence in outgroup judgments (5-point scale)
- Bot informativeness and empathy ratings (5-point scale)

### Pre-Registered Analyses

For each primary outcome, we estimated mixed-effects models of the form:

$$y \sim \text{time} \times \text{learner\_party} + (1 | \text{id})$$

where `time` indexes pre- versus post-interaction measurement and `learner_party` indicates D→R versus R→D learning direction.

## Results

```{r prepare-long-data}
# Prepare long format datasets
accuracy_long <- dat %>%
  select(ResponseId, learner_party, accuracy_pre, accuracy_post) %>%
  pivot_longer(cols = c(accuracy_pre, accuracy_post), names_to = "time",
               names_pattern = "accuracy_(pre|post)", values_to = "error") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

warmth_long <- dat %>%
  select(ResponseId, learner_party, warmth_outgroup_pre, warmth_outgroup_post) %>%
  pivot_longer(cols = c(warmth_outgroup_pre, warmth_outgroup_post), names_to = "time",
               names_pattern = "warmth_outgroup_(pre|post)", values_to = "warmth") %>%
  mutate(time = factor(time, levels = c("pre", "post")))
```

### Preliminaries

Democrats' and Republicans' actual green values and their perceptions of ingroup and outgroup attitudes.

```{r preliminaries, fig.width=10, fig.height=6}
# Prepare data for faceted plot
prelim_data <- dat %>%
  select(learner_party, participant_party, green_own, green_ingroup, green_outgroup_pre, green_outgroup_post) %>%
  pivot_longer(cols = c(green_own, green_ingroup, green_outgroup_pre, green_outgroup_post),
               names_to = "measure_type", values_to = "value") %>%
  mutate(
    measure_type = factor(measure_type,
                          levels = c("green_own", "green_ingroup", "green_outgroup_pre", "green_outgroup_post"),
                          labels = c("Own Attitudes", "Ingroup Perception", "Outgroup Perception (Pre)", "Outgroup Perception (Post)")),
    participant_party = factor(participant_party, levels = c("Democrat", "Republican"))
  )

# Create faceted plot
ggplot(prelim_data, aes(x = participant_party, y = value, fill = participant_party)) +
  stat_summary(fun = mean, geom = "bar", alpha = 0.8) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  facet_wrap(~measure_type, ncol = 4) +
  scale_fill_manual(values = party_colors, name = "Political Party") +
  labs(
    title = "Green Attitudes: Actual and Perceived",
    subtitle = "Own attitudes, ingroup perceptions, and outgroup perceptions before and after interaction",
    x = "Political Party",
    y = "Green Attitude (1-5 scale)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Q1. Do people update their beliefs after interacting with the chatbot?

We examine whether participants changed their beliefs about the outgroup's environmental attitudes from pre- to post-interaction, analyzing both accuracy and warmth.

```{r q1-data-prep}
# Calculate summary statistics for plots
accuracy_summary <- accuracy_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_error = mean(error, na.rm = TRUE),
            se_error = sd(error, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")

warmth_summary <- warmth_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_warmth = mean(warmth, na.rm = TRUE),
            se_warmth = sd(warmth, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")
```

```{r q1-plots, fig.width=10, fig.height=4}
#| layout-ncol: 2

# Accuracy plot
ggplot(accuracy_summary, aes(x = time, y = mean_error, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_error - se_error, ymax = mean_error + se_error), width = 0.1) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(title = "Belief Accuracy", x = "Time", y = "Mean Absolute Error") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")

# Warmth plot
ggplot(warmth_summary, aes(x = time, y = mean_warmth, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_warmth - se_warmth, ymax = mean_warmth + se_warmth), width = 0.1) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(title = "Outgroup Warmth", x = "Time", y = "Mean Warmth") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

```{r q1-models}
# Estimate mixed-effects models
accuracy_model0 <- lmer(error ~ time  + (1 | ResponseId), data = accuracy_long)
warmth_model0 <- lmer(warmth ~ time  + (1 | ResponseId), data = warmth_long)

accuracy_model <- lmer(error ~ time * learner_party + (1 | ResponseId), data = accuracy_long)
warmth_model <- lmer(warmth ~ time * learner_party + (1 | ResponseId), data = warmth_long)

# Display models side by side
modelsummary(
  list(
    "Accuracy" = accuracy_model0, 
    "Warmth" = warmth_model0),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Accuracy is absolute error (lower = more accurate). * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q2. Is belief updating symmetric across political groups?

The primary analyses above test whether Democrats and Republicans show different patterns of belief updating. The key test is the `time × learner_party` interaction in the mixed-effects models. A significant interaction would indicate asymmetric updating across groups.

```{r}
# Display models side by side
modelsummary(
  list(
    "Accuracy" = accuracy_model, 
    "Warmth" = warmth_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Accuracy is absolute error (lower = more accurate). * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q3. Does political extremity predict how much people update?

We explore whether participants' political extremism (distance from the political center) moderates the treatment effect.

```{r extremism-models}
# Add extremism to long data
accuracy_long_ext <- accuracy_long %>%
  left_join(dat %>% select(ResponseId, political_extremism), by = "ResponseId")

warmth_long_ext <- warmth_long %>%
  left_join(dat %>% select(ResponseId, political_extremism), by = "ResponseId")

# Models with extremism interaction
accuracy_extremism_model <- lmer(
  error ~ time * learner_party * political_extremism + (1 | ResponseId),
  data = accuracy_long_ext
)

warmth_extremism_model <- lmer(
  warmth ~ time * learner_party * political_extremism + (1 | ResponseId),
  data = warmth_long_ext
)

# Display models
modelsummary(
  list("Accuracy" = accuracy_extremism_model, "Warmth" = warmth_extremism_model),
  stars = TRUE,
  coef_omit = "Intercept",
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Three-way interaction tests whether extremism moderates differential updating. * p<0.05, ** p<0.01, *** p<0.001"
)
```

### Q4. Is belief updating associated with how the chatbot is perceived?

We examine whether participants who found the chatbot more informative or empathic showed greater belief updating, controlling for pre-interaction values.

```{r process-models}
# Prepare data for regressions
dat_for_reg <- dat %>%
  filter(!is.na(accuracy_pre), !is.na(accuracy_post),
         !is.na(warmth_outgroup_pre), !is.na(warmth_outgroup_post),
         !is.na(info), !is.na(empathy))

# Process measure regressions
accuracy_process_model <- lm(accuracy_post ~ accuracy_pre + info + empathy, data = dat_for_reg)
warmth_process_model <- lm(warmth_outgroup_post ~ warmth_outgroup_pre + info + empathy, data = dat_for_reg)

# Display models
modelsummary(
  list("Accuracy" = accuracy_process_model, "Warmth" = warmth_process_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  notes = "Note: Regressions control for pre-interaction values. * p<0.05, ** p<0.01, *** p<0.001"
)
```

Do perceptions of informativeness and empathy correlate with each other?

```{r}
library(ggpubr)

dat_for_reg %>%
  ggplot(aes(x = empathy, y = info, color = learner_party)) +
  geom_jitter(alpha = 0.6, size = 2.5, width = 0.1, height = 0.1) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    title = "Relationship Between Bot Empathy and Informativeness",
    x = "Empathy Rating (1-5)",
    y = "Informativeness Rating (1-5)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

### Q5. Does engagement ("dose") matter for belief updating?

The pre-registration specified examining whether engagement with the chatbot—operationalized as the number of words typed by participants during the chat—is associated with post-interaction outcomes. We test whether greater engagement predicts more belief updating and warmth change.

```{r engagement-descriptives}
# Descriptive statistics for engagement
engagement_summary <- dat %>%
  summarise(
    mean_turns = mean(user_turn_count, na.rm = TRUE),
    sd_turns = sd(user_turn_count, na.rm = TRUE),
    mean_words = mean(user_word_count, na.rm = TRUE),
    sd_words = sd(user_word_count, na.rm = TRUE)
  )

# Create change scores and log-transformed word count
# No +1 needed for log transform since min word count = 47
dat <- dat %>%
  mutate(
    accuracy_change = accuracy_post - accuracy_pre,  # Negative = improvement
    warmth_change = warmth_outgroup_post - warmth_outgroup_pre,
    log_word_count = log(user_word_count)
  )

cat("Engagement metrics:\n")
cat(sprintf("  Turn count: M = %.2f, SD = %.2f\n",
            engagement_summary$mean_turns, engagement_summary$sd_turns))
cat(sprintf("  Word count: M = %.2f, SD = %.2f\n",
            engagement_summary$mean_words, engagement_summary$sd_turns))
```

#### Does engagement predict belief accuracy improvement?

```{r engagement-accuracy}
# Model: Engagement predicting accuracy change
m_accuracy_turns <- lm(accuracy_change ~ user_turn_count + accuracy_pre + learner_party,
                       data = dat)
m_accuracy_log_words <- lm(accuracy_change ~ log_word_count + accuracy_pre + learner_party,
                           data = dat)

modelsummary(
  list(
    "Turn Count" = m_accuracy_turns,
    "Log(Word Count)" = m_accuracy_log_words
  ),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  coef_rename = c(
    "user_turn_count" = "Turn Count",
    "log_word_count" = "Log(Word Count)",
    "accuracy_pre" = "Baseline Accuracy",
    "learner_partyR→D" = "Learner: R→D"
  )
)
```

Greater engagement—measured by turn count—was `r if(coef(summary(m_accuracy_turns))["user_turn_count", "Pr(>|t|)"] < 0.05) "significantly" else "not significantly"` associated with accuracy change (*b* = `r sprintf("%.4f", coef(m_accuracy_turns)["user_turn_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_accuracy_turns))["user_turn_count", "Pr(>|t|)"])`). Using log-transformed word count, the effect was `r if(coef(summary(m_accuracy_log_words))["log_word_count", "Pr(>|t|)"] < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.4f", coef(m_accuracy_log_words)["log_word_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_accuracy_log_words))["log_word_count", "Pr(>|t|)"])`).

#### Does engagement predict warmth change?

```{r engagement-warmth}
# Model: Engagement predicting warmth change
m_warmth_turns <- lm(warmth_change ~ user_turn_count + warmth_outgroup_pre + learner_party,
                     data = dat)
m_warmth_log_words <- lm(warmth_change ~ log_word_count + warmth_outgroup_pre + learner_party,
                         data = dat)

modelsummary(
  list(
    "Turn Count" = m_warmth_turns,
    "Log(Word Count)" = m_warmth_log_words
  ),
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  coef_rename = c(
    "user_turn_count" = "Turn Count",
    "log_word_count" = "Log(Word Count)",
    "warmth_outgroup_pre" = "Baseline Warmth",
    "learner_partyR→D" = "Learner: R→D"
  )
)
```

Greater engagement—measured by turn count—was `r if(coef(summary(m_warmth_turns))["user_turn_count", "Pr(>|t|)"] < 0.05) "significantly" else "not significantly"` associated with warmth change (*b* = `r sprintf("%.4f", coef(m_warmth_turns)["user_turn_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_warmth_turns))["user_turn_count", "Pr(>|t|)"])`). Using log-transformed word count, the effect was `r if(coef(summary(m_warmth_log_words))["log_word_count", "Pr(>|t|)"] < 0.05) "significant" else "not significant"` (*b* = `r sprintf("%.4f", coef(m_warmth_log_words)["log_word_count"])`, *p* = `r sprintf("%.3f", coef(summary(m_warmth_log_words))["log_word_count", "Pr(>|t|)"])`).

```{r engagement-plots, fig.width=10, fig.height=8}
# Plots with turn count
p1 <- ggplot(dat, aes(x = user_turn_count, y = accuracy_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  stat_cor()+
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = learner_party_colors) +
  labs(
    x = "Turn Count",
    y = "Accuracy Change\n(Negative = Improvement)",
    color = "Learner Party",
    title = "Turn Count and Accuracy Change"
  ) +
  theme_minimal()

p2 <- ggplot(dat, aes(x = user_turn_count, y = warmth_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  stat_cor()+
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = learner_party_colors) +
  labs(
    x = "Turn Count",
    y = "Warmth Change\n(Positive = Increase)",
    color = "Learner Party",
    title = "Turn Count and Warmth Change"
  ) +
  theme_minimal()

# Plots with log word count
p3 <- ggplot(dat, aes(x = log_word_count, y = accuracy_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  stat_cor()+
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = learner_party_colors) +
  labs(
    x = "Log(Word Count)",
    y = "Accuracy Change\n(Negative = Improvement)",
    color = "Learner Party",
    title = "Log(Word Count) and Accuracy Change"
  ) +
  theme_minimal()

p4 <- ggplot(dat, aes(x = log_word_count, y = warmth_change, color = learner_party)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = TRUE) +
  stat_cor()+
  scale_color_manual(values = learner_party_colors) +
  labs(
    x = "Log(Word Count)",
    y = "Warmth Change\n(Positive = Increase)",
    color = "Learner Party",
    title = "Log(Word Count) and Warmth Change"
  ) +
  theme_minimal()

library(patchwork)
(p1 + p2) / (p3 + p4) + plot_layout(guides = "collect")
```

### Q6. Does interacting with the chatbot improve applied judgment?

Participants wrote slogans for marketing energy-saving appliances to the political outgroup.

**DATA AVAILABLE**: Raw slogan text in variable `Q23` (n = `r sum(!is.na(dat$Q23))` responses).

**DATA NEEDED**:
1. Semantic similarity scores (compare to AI-generated responses to detect copying)
2. Quality ratings (human or LLM ratings of slogan fit to target outgroup)

### Q7. Does confidence track accuracy—or diverge from it?

We examine participants' metacognitive awareness by testing (1) whether confidence changes from pre to post, and (2) whether confidence changes track with actual accuracy improvements.

#### Model: Does confidence change pre-to-post?

```{r confidence-model}
# Prepare confidence data in long format
confidence_long <- dat %>%
  select(ResponseId, learner_party, confidence_outgroup_pre, confidence_outgroup_post) %>%
  pivot_longer(cols = c(confidence_outgroup_pre, confidence_outgroup_post),
               names_to = "time", names_pattern = "confidence_outgroup_(pre|post)",
               values_to = "confidence") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

# Calculate summary statistics for plot
confidence_summary <- confidence_long %>%
  group_by(learner_party, time) %>%
  summarise(mean_confidence = mean(confidence, na.rm = TRUE),
            se_confidence = sd(confidence, na.rm = TRUE) / sqrt(n()),
            .groups = "drop")

# Confidence plot
ggplot(confidence_summary, aes(x = time, y = mean_confidence, color = learner_party, group = learner_party)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_confidence - se_confidence, ymax = mean_confidence + se_confidence), width = 0.1) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(title = "Confidence in Outgroup Judgments", x = "Time", y = "Mean Confidence (1-5)") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")

# Mixed-effects models
confidence_model0 <- lmer(confidence ~ time + (1 | ResponseId), data = confidence_long)
confidence_model <- lmer(confidence ~ time * learner_party + (1 | ResponseId), data = confidence_long)

# Display models
modelsummary(
  list("Confidence (Main Effect)" = confidence_model0,
       "Confidence (Interaction)" = confidence_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Confidence rated on 1-5 scale. * p<0.05, ** p<0.01, *** p<0.001"
)
```

#### Correlation: Does confidence change track accuracy improvement?

```{r confidence-calibration, fig.width=8, fig.height=6}
# Compute change scores
calibration_dat <- dat_for_reg %>%
  mutate(
    confidence_change = confidence_outgroup_post - confidence_outgroup_pre,
    accuracy_change = accuracy_post - accuracy_pre  # Negative = improvement
  )

# Create scatter plot with correlation statistics
ggplot(calibration_dat, aes(x = confidence_change, y = accuracy_change, color = learner_party)) +
  geom_point(alpha = 0.6, size = 2.5) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1) +
  stat_cor(aes(label = paste((..r.label..), ..p.label.., sep = "~`,`~")),
           method = "pearson", show.legend = FALSE, size = 3.5) +
  scale_color_manual(values = learner_party_colors, name = "Learner Party") +
  labs(
    x = "Confidence Change (Post - Pre)",
    y = "Accuracy Change (Post - Pre)\nNegative = Improvement",
    title = "Confidence-Accuracy Calibration",
    subtitle = "Does confidence change track with accuracy improvement?",
    caption = "Note: Negative correlation would indicate increased confidence associated with improved accuracy"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    plot.caption = element_text(hjust = 0, size = 9, color = "gray40"),
    legend.position = "bottom"
  )
```

### Robustness Checks

#### Warmth Difference Score

Following common practice in the affective polarization literature, we examine warmth using a difference score (outgroup - ingroup).

```{r warmth-difference}
# Prepare warmth difference data
warmth_diff_long <- dat %>%
  select(ResponseId, learner_party, warmth_diff_pre, warmth_diff_post) %>%
  pivot_longer(cols = c(warmth_diff_pre, warmth_diff_post), names_to = "time",
               names_pattern = "warmth_diff_(pre|post)", values_to = "warmth_diff") %>%
  mutate(time = factor(time, levels = c("pre", "post")))

# Mixed-effects model
warmth_diff_model <- lmer(warmth_diff ~ time * learner_party + (1 | ResponseId), data = warmth_diff_long)

# Display model
modelsummary(
  list("Warmth Difference" = warmth_diff_model),
  stars = TRUE,
  gof_map = c("nobs", "r.squared"),
  notes = "Note: Warmth difference = outgroup - ingroup. Positive time coefficient indicates reduced polarization. * p<0.05, ** p<0.01, *** p<0.001"
)
```

## Discussion

### Summary of Findings

This pilot study tested whether interacting with an AI chatbot representing a political outgroup could improve participants' understanding of and warmth toward that outgroup. Using a within-subjects pre-post design, we examined changes in outgroup belief accuracy and outgroup warmth following an AI-mediated interaction.

### Primary Hypotheses

**Hypothesis 1: Outgroup Belief Accuracy**

We hypothesized that participants would report more accurate beliefs about the outgroup's environmental attitudes after interacting with the AI chatbot. Accuracy was operationalized as the absolute difference between participants' estimates and the outgroup's actual mean green attitudes. The time coefficient in the mixed-effects model indicates whether accuracy improved (error decreased) from pre to post, while the interaction term tests whether this change differed between Democrat and Republican learners.

**Hypothesis 2: Outgroup Warmth**

We hypothesized that participants would feel warmer toward the political outgroup after the interaction. The time coefficient indicates whether warmth increased from pre to post, while the interaction term tests whether Democrats and Republicans showed different patterns of change.

### Exploratory Findings

Secondary analyses examined confidence in outgroup judgments and perceptions of the bot's informativeness and empathy. Confidence ratings provide insight into participants' metacognitive awareness of their knowledge about the outgroup. Bot perception ratings help illuminate potential mechanisms—if participants found the bot informative and empathic, this may mediate changes in accuracy and warmth.

### Implications for Marketing Practice

If the hypothesized effects are supported, this research suggests that AI-mediated interactions can serve as a scalable tool for reducing political misperceptions in consumer research. Marketers often struggle to understand ideologically diverse consumer segments, relying on stereotypes or costly focus groups. AI chatbots could provide an accessible method for gaining insight into outgroup consumer preferences and values.

This approach may be particularly valuable for marketing environmentally responsible products, where political divides can lead to misperceptions about consumer attitudes. Understanding that political outgroups may be more environmentally conscious than stereotypes suggest could inform more effective cross-partisan messaging strategies.

### Limitations

Several limitations should be noted. The pilot sample consists primarily of test and preview responses, limiting statistical power and generalizability. The environmental attitude domain may not generalize to other consumer preferences. Belief accuracy depends on having adequate sample sizes within each political group to compute reliable actual outgroup means. The study examines only immediate post-interaction effects; durability of any changes remains unknown.

Additionally, participants interacted with an AI chatbot rather than actual outgroup members. While this approach offers scalability advantages, it raises questions about whether insights gained from AI interactions transfer to understanding real outgroup members. The chatbot was prompted to represent the outgroup but may not fully capture the diversity of views within each political group.

### Next Steps

The full study will recruit N = 500 participants from a representative sample. Key priorities include examining whether bot informativeness and empathy mediate changes in warmth and accuracy, analyzing participant-generated marketing slogans for energy-saving appliances, and testing for heterogeneous effects by political extremity and prior outgroup attitudes. Exploratory analyses will examine engagement (words typed during chat) as a predictor of outcomes.

Future research should examine the durability of effects over time, test generalizability to other product categories and consumer attitudes beyond environmental responsibility, and compare AI-mediated learning to alternative interventions such as reading testimonials from outgroup members or interacting with human outgroup representatives.

## Appendix

### Descriptive Statistics

```{r descriptives-actual-attitudes}
# Actual environmental attitudes by party
dat %>%
  group_by(participant_party) %>%
  summarise(
    mean_green = mean(green_own, na.rm = TRUE),
    sd_green = sd(green_own, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    participant_party = "Political Party",
    mean_green = "Mean Green Attitude",
    sd_green = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_green, sd_green), decimals = 2) %>%
  tab_header(
    title = "Actual Environmental Attitudes by Political Party",
    subtitle = "Self-reported green attitudes (1-5 scale)"
  )
```

```{r descriptives-accuracy}
# Accuracy by time and learner party
accuracy_long %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_error = mean(error, na.rm = TRUE),
    sd_error = sd(error, na.rm = TRUE),
    n = sum(!is.na(error)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_error = "Mean Error",
    sd_error = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_error, sd_error), decimals = 3) %>%
  tab_header(
    title = "Outgroup Belief Accuracy",
    subtitle = "Absolute error (lower = more accurate)"
  )
```

```{r descriptives-warmth}
# Warmth by time and learner party
warmth_long %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_warmth = mean(warmth, na.rm = TRUE),
    sd_warmth = sd(warmth, na.rm = TRUE),
    n = sum(!is.na(warmth)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_warmth = "Mean Warmth",
    sd_warmth = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_warmth, sd_warmth), decimals = 2) %>%
  tab_header(
    title = "Outgroup Warmth (Feeling Thermometer)",
    subtitle = "By learner party and time point (0-100 scale)"
  )
```

```{r descriptives-extremism}
# Political extremism by learner party
dat %>%
  group_by(learner_party) %>%
  summarise(
    mean_extremism = mean(political_extremism, na.rm = TRUE),
    sd_extremism = sd(political_extremism, na.rm = TRUE),
    min_extremism = min(political_extremism, na.rm = TRUE),
    max_extremism = max(political_extremism, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    mean_extremism = "Mean",
    sd_extremism = "SD",
    min_extremism = "Min",
    max_extremism = "Max"
  ) %>%
  fmt_number(columns = c(mean_extremism, sd_extremism, min_extremism, max_extremism), decimals = 2) %>%
  tab_header(
    title = "Political Extremism by Learner Party",
    subtitle = "Distance from political center (0-50 scale)"
  )
```

```{r descriptives-bot-perceptions}
# Bot perceptions by learner party
dat %>%
  select(learner_party, info, empathy) %>%
  pivot_longer(cols = c(info, empathy), names_to = "measure", values_to = "rating") %>%
  mutate(measure = case_when(
    measure == "info" ~ "Informativeness",
    measure == "empathy" ~ "Empathy",
    TRUE ~ measure
  )) %>%
  group_by(learner_party, measure) %>%
  summarise(
    mean_rating = mean(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    n = sum(!is.na(rating)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    measure = "Measure",
    mean_rating = "Mean Rating",
    sd_rating = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_rating, sd_rating), decimals = 2) %>%
  tab_header(
    title = "Bot Perception Ratings",
    subtitle = "By learner party (1-5 scale)"
  )
```

```{r descriptives-confidence}
# Confidence by time and learner party
dat %>%
  select(ResponseId, learner_party, confidence_outgroup_pre, confidence_outgroup_post) %>%
  pivot_longer(cols = c(confidence_outgroup_pre, confidence_outgroup_post),
               names_to = "time", names_pattern = "confidence_outgroup_(pre|post)",
               values_to = "confidence") %>%
  mutate(time = factor(time, levels = c("pre", "post"))) %>%
  group_by(learner_party, time) %>%
  summarise(
    mean_confidence = mean(confidence, na.rm = TRUE),
    sd_confidence = sd(confidence, na.rm = TRUE),
    n = sum(!is.na(confidence)),
    .groups = "drop"
  ) %>%
  gt() %>%
  cols_label(
    learner_party = "Learner Party",
    time = "Time",
    mean_confidence = "Mean Confidence",
    sd_confidence = "SD",
    n = "N"
  ) %>%
  fmt_number(columns = c(mean_confidence, sd_confidence), decimals = 2) %>%
  tab_header(
    title = "Confidence in Outgroup Judgments",
    subtitle = "By learner party and time point (1-5 scale)"
  )
```

### Data Availability

Raw data: [data/raw/qualtrics.parquet](../data/raw/qualtrics.parquet)

Cleaned data: [output/cleaned_data.parquet](../output/cleaned_data.parquet)

### Code Availability

Data cleaning script: [src/clean_data.R](../src/clean_data.R)

### Pre-Registration

This study was pre-registered prior to data collection. See [docs/pre-registration.md](../docs/pre-registration.md) for complete details including hypotheses, measures, sample size justification, and planned analyses.

### Session Information

```{r session-info}
sessionInfo()
```
