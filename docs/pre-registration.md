### 1) Data Collection

**Have any data been collected for this study already?**  
No, no data have been collected for this study yet.

### 2) Hypothesis

The primary hypothesis is that interacting with an AI chatbot prompted to represent a political outgroup will improve participants' perceptions of that outgroup.

Specifically, we hypothesize that after interacting with the chatbot, participants will:
(1) Report more accurate beliefs about the outgroup's attitudes toward environmentally responsible consumption.
(2) Feel warmer toward the political outgroup.

### 3) Dependent Variables

**Primary dependent variables:**

**(P1) Outgroup belief accuracy.**  
Participants will estimate the average political outgroup's agreement with six statements about environmental responsibility (5-point Likert scale). Accuracy will be operationalized as the absolute difference between participants' estimates and the outgroup's actual mean self-reports (computed from the corresponding participants who identify with that group).

**(P2) Outgroup warmth.**  
Measured using a feeling thermometer ranging from 0 (“cold”) to 100 (“warm”) toward the political outgroup.

**Secondary dependent variables:**

**(P3) Confidence in outgroup judgments.**  
Self-reported confidence in the accuracy of participants' predictions about the outgroup (5-point scale).

**(P4) Slogan quality (exploratory).**  
Participants will write a short slogan promoting energy-saving home appliances to the political outgroup. These responses will be analyzed exploratorily.

### 4) Conditions

All participants complete the same procedure. There are no experimental conditions.

Participants interact with a chatbot prompted to represent their political outgroup. Political ingroup and outgroup status are defined based on participants' self-reported political orientation.

### 5) Analyses

All primary analyses will examine within-person change from pre- to post-interaction and whether this change differs by participant group: Democrats learning about Republicans (D→R) versus Republicans learning about Democrats (R→D). For each primary outcome (outgroup belief accuracy and outgroup warmth), we will estimate models of the form [y ~ time * learner_party + (1 | id)] where *time* indexes pre- versus post-interaction measurement and *learner_party* indicates D→R versus R→D. The coefficient on *time* captures average pre–post change, and the *time × learner_party* interaction tests whether change differs between groups.
### 6) Outliers and Exclusions

No data will be excluded from the main analyses.

For the exploratory slogan task only, we will assess potential copying by computing semantic similarity between participants’ slogans and AI-generated responses produced by ChatGPT, Claude, and Gemini using the same prompt. Slogans with similarity values more than 3 SDs above the mean will be excluded from exploratory slogan analyses only.


### 7) Sample Size

We will collect data from **N = 500** participants.

### 8) Other Pre-Registered Analyses

**Process measures (exploratory).** We will measure perceived informativeness and perceived empathy of the chatbot using single-item ratings. As exploratory analyses, we will examine whether these measures are associated with post-interaction outgroup warmth and post-interaction outgroup belief accuracy, controlling for pre-interaction values, using linear regression models of the form:

post ~ pre + informativeness + empathy

As an additional exploratory analysis, we will examine whether engagement with the chatbot—operationalized as the **number of words typed by the participant during the chat**—is associated with post-interaction outcomes, controlling for pre-interaction values.
  
**Slogan analysis (exploratory).**
The slogan-writing task will be analyzed exploratorily using human or automated ratings of perceived fit to the target group.